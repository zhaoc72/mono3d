#!/usr/bin/env python3
"""
å®Œæ•´çš„å¯è§†åŒ–æµ‹è¯•è„šæœ¬ - éªŒè¯æ¯ä¸ªä¸­é—´æ­¥éª¤
"""

import sys
import yaml
import torch
import numpy as np
import cv2
from pathlib import Path
import matplotlib.pyplot as plt

sys.path.insert(0, '/media/pc/D/zhaochen/mono3d/mono3d')

from src.dinov3_feature import DINOv3FeatureExtractor, Dinov3Config
from src.sam2_segmenter import SAM2Segmenter, Sam2Config
from src.inference_pipeline import ZeroShotSegmentationPipeline, PipelineConfig
from src.prompt_generator import ClusterConfig, PromptConfig
from src.data_loader import load_image
from src.utils import to_torch_dtype

print("=" * 80)
print("å®Œæ•´å¯è§†åŒ–æµ‹è¯• - DINOv3 + SAM2 åˆ†å‰²")
print("=" * 80)

# ==================== é…ç½® ====================
image_path = "/media/pc/D/datasets/vkitti2/Scene01/clone/frames/rgb/Camera_0/rgb_00061.jpg"
output_dir = Path("/media/pc/D/zhaochen/mono3d/mono3d/outputs/complete_visualization_test")
output_dir.mkdir(exist_ok=True, parents=True)

print(f"\nè¾“å…¥å›¾åƒ: {image_path}")
print(f"è¾“å‡ºç›®å½•: {output_dir}")

# ==================== åŠ è½½å›¾åƒ ====================
print("\n" + "=" * 80)
print("æ­¥éª¤ 1: åŠ è½½å›¾åƒ")
print("=" * 80)

sample = load_image(image_path)
image = sample.image
print(f"âœ… å›¾åƒå°ºå¯¸: {image.shape}")
print(f"   é«˜åº¦: {image.shape[0]}")
print(f"   å®½åº¦: {image.shape[1]}")
print(f"   é€šé“: {image.shape[2]}")

# ä¿å­˜åŸå›¾
cv2.imwrite(
    str(output_dir / "step1_original.jpg"),
    cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
)

# ==================== åˆå§‹åŒ–æ¨¡å‹ ====================
print("\n" + "=" * 80)
print("æ­¥éª¤ 2: åˆå§‹åŒ– DINOv3")
print("=" * 80)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
dtype = torch.float16 if device.type == "cuda" else torch.float32

print(f"è®¾å¤‡: {device}")
print(f"ç²¾åº¦: {dtype}")

dinov3_cfg = Dinov3Config(
    repo_or_dir="/media/pc/D/zhaochen/mono3d/dinov3",
    model_name="dinov3_vith16plus",
    checkpoint_path="/media/pc/D/zhaochen/mono3d/dinov3/checkpoints/dinov3_vith16plus.pth",
    use_torch_hub=True,
    torchhub_source="local",
    output_layers=[4, 8, 12],
    layer_weights=[0.2, 0.3, 0.5],
    fusion_method="weighted_concat",
    enable_objectness=True
)

extractor = DINOv3FeatureExtractor(dinov3_cfg, device, dtype)
print("âœ… DINOv3 åˆå§‹åŒ–æˆåŠŸ")
print(f"   èåˆå±‚: {dinov3_cfg.output_layers}")
print(f"   å±‚æƒé‡: {dinov3_cfg.layer_weights}")
print(f"   èåˆæ–¹æ³•: {dinov3_cfg.fusion_method}")

# ==================== æå–ç‰¹å¾ ====================
print("\n" + "=" * 80)
print("æ­¥éª¤ 3: æå– DINOv3 ç‰¹å¾")
print("=" * 80)

feats = extractor.extract_features(image)

patch_map = feats["patch_map"]
if hasattr(patch_map, "detach"):
    patch_map = patch_map.detach().cpu().numpy()

grid_h, grid_w, feat_dim = patch_map.shape

print(f"âœ… ç‰¹å¾æå–æˆåŠŸ")
print(f"   Patch grid: {grid_h}x{grid_w}")
print(f"   ç‰¹å¾ç»´åº¦: {feat_dim}")
print(f"   æœŸæœ›ç»´åº¦: {1280 * len(dinov3_cfg.output_layers)} (3å±‚ Ã— 1280)")

# å¯è§†åŒ– Objectness Map
if feats.get('objectness_map') is not None:
    objectness = feats['objectness_map']
    print(f"   Objectness Map: {objectness.shape}")
    print(f"   èŒƒå›´: [{objectness.min():.3f}, {objectness.max():.3f}]")
    
    # ä¸Šé‡‡æ ·åˆ°åŸå›¾å°ºå¯¸
    objectness_upsampled = cv2.resize(
        objectness,
        (image.shape[1], image.shape[0]),
        interpolation=cv2.INTER_CUBIC
    )
    
    # ä¿å­˜çƒ­å›¾
    obj_vis = (objectness_upsampled * 255).astype(np.uint8)
    obj_colored = cv2.applyColorMap(obj_vis, cv2.COLORMAP_JET)
    cv2.imwrite(str(output_dir / "step3a_objectness.jpg"), obj_colored)
    
    # å åŠ åˆ°åŸå›¾
    overlay = cv2.addWeighted(
        cv2.cvtColor(image, cv2.COLOR_RGB2BGR), 0.6,
        obj_colored, 0.4, 0
    )
    cv2.imwrite(str(output_dir / "step3b_objectness_overlay.jpg"), overlay)
    print(f"   âœ… Objectness å¯è§†åŒ–å·²ä¿å­˜")

# ==================== èšç±» ====================
print("\n" + "=" * 80)
print("æ­¥éª¤ 4: ç‰¹å¾èšç±»")
print("=" * 80)

cluster_cfg = ClusterConfig(
    num_clusters=6,
    min_region_area=400,
    use_objectness_filter=True,
    objectness_threshold=0.3
)

from src.prompt_generator import kmeans_cluster, labels_to_regions

# K-Means èšç±»
features = patch_map.reshape(-1, feat_dim)
labels, centroids = kmeans_cluster(features, cluster_cfg)
label_map = labels.reshape(grid_h, grid_w)

print(f"âœ… èšç±»å®Œæˆ")
print(f"   èšç±»æ•°: {cluster_cfg.num_clusters}")
print(f"   æ ‡ç­¾å›¾: {label_map.shape}")
print(f"   å”¯ä¸€æ ‡ç­¾: {np.unique(label_map)}")

# å¯è§†åŒ–èšç±»ç»“æœ
label_vis = (label_map * 255 / label_map.max()).astype(np.uint8)
label_colored = cv2.applyColorMap(label_vis, cv2.COLORMAP_JET)
label_colored_upsampled = cv2.resize(
    label_colored,
    (image.shape[1], image.shape[0]),
    interpolation=cv2.INTER_NEAREST
)
cv2.imwrite(str(output_dir / "step4a_clusters.jpg"), label_colored_upsampled)

overlay = cv2.addWeighted(
    cv2.cvtColor(image, cv2.COLOR_RGB2BGR), 0.6,
    label_colored_upsampled, 0.4, 0
)
cv2.imwrite(str(output_dir / "step4b_clusters_overlay.jpg"), overlay)
print(f"   âœ… èšç±»å¯è§†åŒ–å·²ä¿å­˜")

# ==================== ç”Ÿæˆå€™é€‰åŒºåŸŸ ====================
print("\n" + "=" * 80)
print("æ­¥éª¤ 5: ç”Ÿæˆå€™é€‰åŒºåŸŸ")
print("=" * 80)

proposals = labels_to_regions(
    label_map,
    image.shape[:2],
    cluster_cfg,
    objectness_map=feats.get('objectness_map')
)

print(f"âœ… å€™é€‰åŒºåŸŸç”Ÿæˆå®Œæˆ")
print(f"   æ€»å€™é€‰æ•°: {len(proposals)}")

if proposals:
    print(f"\n   å‰ 5 ä¸ªå€™é€‰åŒºåŸŸ:")
    for i, prop in enumerate(proposals[:5]):
        x0, y0, x1, y1 = prop.bbox
        area = (x1 - x0) * (y1 - y0)
        print(f"     {i}: bbox=[{x0:4d},{y0:4d},{x1:4d},{y1:4d}], "
              f"area={area:6.0f}, objectness={prop.objectness:.3f}")
    
    # å¯è§†åŒ–å€™é€‰æ¡†
    img_with_boxes = image.copy()
    for i, prop in enumerate(proposals):
        x0, y0, x1, y1 = prop.bbox
        cv2.rectangle(img_with_boxes, (x0, y0), (x1, y1), (0, 255, 0), 2)
        cv2.putText(
            img_with_boxes, f"{i}", (x0, y0-5),
            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2
        )
    
    cv2.imwrite(
        str(output_dir / "step5_proposals.jpg"),
        cv2.cvtColor(img_with_boxes, cv2.COLOR_RGB2BGR)
    )
    print(f"   âœ… å€™é€‰æ¡†å¯è§†åŒ–å·²ä¿å­˜")
else:
    print("   âš ï¸ æ²¡æœ‰ç”Ÿæˆä»»ä½•å€™é€‰åŒºåŸŸ!")

# ==================== ç”Ÿæˆ SAM2 Prompts ====================
print("\n" + "=" * 80)
print("æ­¥éª¤ 6: ç”Ÿæˆ SAM2 Prompts")
print("=" * 80)

prompt_cfg = PromptConfig(
    include_boxes=True,
    include_points=True,
    point_strategy="centroid"
)

from src.prompt_generator import expand_region_instances, proposals_to_prompts

instance_proposals = expand_region_instances(
    proposals,
    prompt_cfg,
    cluster_cfg,
    patch_map,
    image.shape[:2]
)

boxes, points, labels_list = proposals_to_prompts(
    instance_proposals,
    prompt_cfg,
    patch_map=patch_map,
    image_shape=image.shape[:2],
    cluster_config=cluster_cfg
)

print(f"âœ… Prompts ç”Ÿæˆå®Œæˆ")
print(f"   å®ä¾‹æ•°: {len(instance_proposals)}")
print(f"   Boxes: {len(boxes)}")
print(f"   Points: {len([p for p in points if p])}")

# å¯è§†åŒ– boxes + points
if boxes:
    img_with_prompts = image.copy()
    for i, (box, pts) in enumerate(zip(boxes, points)):
        x0, y0, x1, y1 = box
        cv2.rectangle(img_with_prompts, (x0, y0), (x1, y1), (0, 255, 0), 2)
        
        if pts:
            for px, py in pts:
                cv2.circle(img_with_prompts, (px, py), 5, (255, 0, 0), -1)
    
    cv2.imwrite(
        str(output_dir / "step6_prompts.jpg"),
        cv2.cvtColor(img_with_prompts, cv2.COLOR_RGB2BGR)
    )
    print(f"   âœ… Prompts å¯è§†åŒ–å·²ä¿å­˜")

# ==================== åˆå§‹åŒ– SAM2 ====================
print("\n" + "=" * 80)
print("æ­¥éª¤ 7: åˆå§‹åŒ– SAM2")
print("=" * 80)

sam2_cfg = Sam2Config(
    backend="official",
    checkpoint_path="/media/pc/D/zhaochen/mono3d/sam2/checkpoints/sam2.1_hiera_large.pt",
    model_config="sam2.1/sam2.1_hiera_l"
)

segmenter = SAM2Segmenter(sam2_cfg, device, dtype)
print("âœ… SAM2 åˆå§‹åŒ–æˆåŠŸ")

# ==================== æ‰§è¡Œåˆ†å‰² ====================
print("\n" + "=" * 80)
print("æ­¥éª¤ 8: æ‰§è¡Œ SAM2 åˆ†å‰²")
print("=" * 80)

masks = segmenter.segment_batched(
    image,
    boxes,
    points=points if points else None,
    labels=labels_list if labels_list else None,
    batch_size=32
)

print(f"âœ… åˆ†å‰²å®Œæˆ")
print(f"   ç”Ÿæˆæ©ç : {len(masks)}")

# åˆ†ææ©ç 
area_threshold = 100
valid_masks = []
total_area = 0

print(f"\n   æ©ç è¯¦æƒ… (é¢ç§¯é˜ˆå€¼: {area_threshold}):")
print(f"   {'ç´¢å¼•':<6} {'é¢ç§¯':<10} {'çŠ¶æ€':<6} {'å æ¯”%':<8}")
print("   " + "-" * 40)

for i, mask in enumerate(masks):
    area = int(mask.astype(np.uint8).sum())
    total_area += area
    
    passed = area >= area_threshold
    if passed:
        valid_masks.append(mask)
    
    ratio = area / (image.shape[0] * image.shape[1]) * 100
    status = "âœ…" if passed else "âŒ"
    
    if i < 10:  # åªæ‰“å°å‰10ä¸ª
        print(f"   {i:<6} {area:<10} {status:<6} {ratio:>6.2f}%")

if len(masks) > 10:
    print(f"   ... (è¿˜æœ‰ {len(masks) - 10} ä¸ª)")

print(f"\n   æ€»ç»“:")
print(f"     - æ€»æ©ç : {len(masks)}")
print(f"     - æœ‰æ•ˆæ©ç : {len(valid_masks)} ({len(valid_masks)/len(masks)*100:.1f}%)")
print(f"     - å¹³å‡é¢ç§¯: {total_area/len(masks):.0f}")

# å¯è§†åŒ–æ‰€æœ‰æ©ç 
if masks:
    combined = np.zeros_like(image)
    for i, mask in enumerate(valid_masks if valid_masks else masks):
        color = np.array([
            (i * 50) % 255,
            (i * 80 + 60) % 255,
            (i * 120 + 30) % 255
        ], dtype=np.uint8)
        combined[mask.astype(bool)] = color
    
    cv2.imwrite(
        str(output_dir / "step8a_masks.jpg"),
        cv2.cvtColor(combined, cv2.COLOR_RGB2BGR)
    )
    
    overlay = cv2.addWeighted(
        cv2.cvtColor(image, cv2.COLOR_RGB2BGR), 0.5,
        cv2.cvtColor(combined, cv2.COLOR_RGB2BGR), 0.5, 0
    )
    cv2.imwrite(str(output_dir / "step8b_masks_overlay.jpg"), overlay)
    
    print(f"   âœ… æ©ç å¯è§†åŒ–å·²ä¿å­˜")

# ==================== åˆ›å»ºå®Œæ•´å¯¹æ¯”å›¾ ====================
print("\n" + "=" * 80)
print("æ­¥éª¤ 9: åˆ›å»ºå®Œæ•´å¯¹æ¯”å›¾")
print("=" * 80)

fig, axes = plt.subplots(2, 4, figsize=(20, 10))
fig.suptitle('DINOv3 + SAM2 åˆ†å‰²æµç¨‹', fontsize=16, fontweight='bold')

# 1. åŸå›¾
axes[0, 0].imshow(image)
axes[0, 0].set_title('1. åŸå§‹å›¾åƒ', fontsize=12, fontweight='bold')
axes[0, 0].axis('off')

# 2. Objectness
if feats.get('objectness_map') is not None:
    axes[0, 1].imshow(objectness_upsampled, cmap='hot')
    axes[0, 1].set_title('2. Objectness Map', fontsize=12, fontweight='bold')
    axes[0, 1].axis('off')
else:
    axes[0, 1].axis('off')

# 3. èšç±»
label_rgb = cv2.cvtColor(label_colored_upsampled, cv2.COLOR_BGR2RGB)
axes[0, 2].imshow(label_rgb)
axes[0, 2].set_title('3. ç‰¹å¾èšç±»', fontsize=12, fontweight='bold')
axes[0, 2].axis('off')

# 4. å€™é€‰åŒºåŸŸ
if proposals:
    axes[0, 3].imshow(img_with_boxes)
    axes[0, 3].set_title(f'4. å€™é€‰åŒºåŸŸ ({len(proposals)}ä¸ª)', fontsize=12, fontweight='bold')
    axes[0, 3].axis('off')
else:
    axes[0, 3].axis('off')

# 5. Prompts
if boxes:
    axes[1, 0].imshow(img_with_prompts)
    axes[1, 0].set_title(f'5. SAM2 Prompts', fontsize=12, fontweight='bold')
    axes[1, 0].axis('off')
else:
    axes[1, 0].axis('off')

# 6. åˆ†å‰²æ©ç 
if masks:
    axes[1, 1].imshow(combined)
    axes[1, 1].set_title(f'6. åˆ†å‰²æ©ç  ({len(valid_masks)}ä¸ª)', fontsize=12, fontweight='bold')
    axes[1, 1].axis('off')
else:
    axes[1, 1].axis('off')

# 7. å åŠ ç»“æœ
if masks:
    overlay_rgb = cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB)
    axes[1, 2].imshow(overlay_rgb)
    axes[1, 2].set_title('7. æœ€ç»ˆç»“æœ', fontsize=12, fontweight='bold')
    axes[1, 2].axis('off')
else:
    axes[1, 2].axis('off')

# 8. ç»Ÿè®¡ä¿¡æ¯
axes[1, 3].axis('off')
stats_text = f"""
ç»Ÿè®¡ä¿¡æ¯:

å›¾åƒå°ºå¯¸: {image.shape[1]}Ã—{image.shape[0]}
ç‰¹å¾ç»´åº¦: {feat_dim}

èšç±»æ•°: {cluster_cfg.num_clusters}
å€™é€‰åŒºåŸŸ: {len(proposals)}
å®ä¾‹æ•°: {len(instance_proposals)}

æ€»æ©ç : {len(masks)}
æœ‰æ•ˆæ©ç : {len(valid_masks)}
æœ‰æ•ˆç‡: {len(valid_masks)/len(masks)*100:.1f}%
"""
axes[1, 3].text(0.1, 0.5, stats_text, fontsize=11, verticalalignment='center', family='monospace')
axes[1, 3].set_title('8. ç»Ÿè®¡ä¿¡æ¯', fontsize=12, fontweight='bold')

plt.tight_layout()
plt.savefig(output_dir / "step9_complete_comparison.jpg", dpi=150, bbox_inches='tight')
plt.close()

print("âœ… å®Œæ•´å¯¹æ¯”å›¾å·²ä¿å­˜")

# ==================== ç”Ÿæˆ README ====================
readme_content = f"""# DINOv3 + SAM2 åˆ†å‰²å¯è§†åŒ–ç»“æœ

## æµ‹è¯•å›¾åƒ
- è·¯å¾„: {image_path}
- å°ºå¯¸: {image.shape[1]}Ã—{image.shape[0]}

## å¤„ç†æµç¨‹

### step1_original.jpg
åŸå§‹è¾“å…¥å›¾åƒ

### step3a_objectness.jpg & step3b_objectness_overlay.jpg
DINOv3 Objectness Map - æ˜¾ç¤ºæ¯ä¸ªåŒºåŸŸæ˜¯å¦ä¸ºç‰©ä½“çš„ç½®ä¿¡åº¦

### step4a_clusters.jpg & step4b_clusters_overlay.jpg
K-Means ç‰¹å¾èšç±»ç»“æœ ({cluster_cfg.num_clusters}ä¸ªèšç±»)

### step5_proposals.jpg
å€™é€‰åŒºåŸŸ (ç»¿è‰²æ¡†) - å…± {len(proposals)} ä¸ª

### step6_prompts.jpg
SAM2 Prompts - ç»¿è‰²æ¡†=bounding boxes, çº¢ç‚¹=æ­£æ ·æœ¬ç‚¹

### step8a_masks.jpg & step8b_masks_overlay.jpg
æœ€ç»ˆåˆ†å‰²æ©ç  - å…± {len(valid_masks)} ä¸ªæœ‰æ•ˆæ©ç 

### step9_complete_comparison.jpg
å®Œæ•´æµç¨‹å¯¹æ¯”å›¾

## å…³é”®å‚æ•°
- DINOv3 èåˆå±‚: {dinov3_cfg.output_layers}
- å±‚æƒé‡: {dinov3_cfg.layer_weights}
- èåˆæ–¹æ³•: {dinov3_cfg.fusion_method}
- èšç±»æ•°: {cluster_cfg.num_clusters}
- Objectness é˜ˆå€¼: {cluster_cfg.objectness_threshold}
- é¢ç§¯é˜ˆå€¼: {area_threshold}

## ç»“æœç»Ÿè®¡
- å€™é€‰åŒºåŸŸ: {len(proposals)}
- ç”Ÿæˆæ©ç : {len(masks)}
- æœ‰æ•ˆæ©ç : {len(valid_masks)}
- æœ‰æ•ˆç‡: {len(valid_masks)/len(masks)*100:.1f}%
"""

with open(output_dir / "README.md", "w", encoding="utf-8") as f:
    f.write(readme_content)

# ==================== å®Œæˆ ====================
print("\n" + "=" * 80)
print("âœ… æµ‹è¯•å®Œæˆ!")
print("=" * 80)

print(f"\nğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {output_dir}/")
print("\nç”Ÿæˆçš„æ–‡ä»¶:")
print("  step1_original.jpg           - åŸå§‹å›¾åƒ")
print("  step3a_objectness.jpg        - Objectness çƒ­å›¾")
print("  step3b_objectness_overlay.jpg - Objectness å åŠ ")
print("  step4a_clusters.jpg          - èšç±»ç»“æœ")
print("  step4b_clusters_overlay.jpg  - èšç±»å åŠ ")
print("  step5_proposals.jpg          - å€™é€‰åŒºåŸŸ")
print("  step6_prompts.jpg            - SAM2 Prompts")
print("  step8a_masks.jpg             - åˆ†å‰²æ©ç ")
print("  step8b_masks_overlay.jpg     - æ©ç å åŠ ")
print("  step9_complete_comparison.jpg - å®Œæ•´å¯¹æ¯”")
print("  README.md                    - è¯¦ç»†è¯´æ˜")

print("\n" + "=" * 80)