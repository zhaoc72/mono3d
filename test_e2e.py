#!/usr/bin/env python3
"""
ç«¯åˆ°ç«¯æµ‹è¯•è„šæœ¬ - éªŒè¯å®Œæ•´ Pipeline
æµ‹è¯•æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½çš„é›†æˆ
"""

import sys
import yaml
import torch
import numpy as np
import cv2
from pathlib import Path

sys.path.insert(0, '/media/pc/D/zhaochen/mono3d/mono3d')

from src.dinov3_feature import DINOv3FeatureExtractor, Dinov3Config
from src.sam2_segmenter import SAM2Segmenter, Sam2Config
from src.inference_pipeline import ZeroShotSegmentationPipeline, PipelineConfig
from src.prompt_generator import ClusterConfig, PromptConfig
from src.superpixel_helper import SuperpixelConfig
from src.graph_clustering import GraphClusterConfig
from src.density_clustering import DensityClusterConfig
from src.crf_refinement import CRFConfig
from src.data_loader import load_image
from src.utils import to_torch_dtype, ensure_directory

print("=" * 80)
print("ç«¯åˆ°ç«¯ Pipeline æµ‹è¯•")
print("=" * 80)


def test_basic_pipeline():
    """æµ‹è¯•åŸºç¡€ Pipelineï¼ˆæœ€ç®€é…ç½®ï¼‰"""
    print("\n" + "=" * 80)
    print("æµ‹è¯• 1: åŸºç¡€ Pipeline")
    print("=" * 80)
    
    try:
        # åŠ è½½å›¾åƒ
        image_path = "/media/pc/D/datasets/vkitti2/Scene01/clone/frames/rgb/Camera_0/rgb_00061.jpg"
        sample = load_image(image_path)
        print(f"âœ… å›¾åƒåŠ è½½: {sample.image.shape}")
        
        # é…ç½®
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        dtype = torch.float16 if device.type == "cuda" else torch.float32
        
        dinov3_cfg = Dinov3Config(
            repo_or_dir="/media/pc/D/zhaochen/mono3d/dinov3",
            model_name="dinov3_vith16plus",
            checkpoint_path="/media/pc/D/zhaochen/mono3d/dinov3/checkpoints/dinov3_vith16plus.pth",
            use_torch_hub=True,
            torchhub_source="local",
            enable_objectness=True
        )
        
        sam2_cfg = Sam2Config(
            backend="official",
            checkpoint_path="/media/pc/D/zhaochen/mono3d/sam2/checkpoints/sam2.1_hiera_large.pt",
            model_config="sam2.1/sam2.1_hiera_l"
        )
        
        cluster_cfg = ClusterConfig(
            num_clusters=6,
            min_region_area=400,
            use_objectness_filter=True
        )
        
        prompt_cfg = PromptConfig(
            include_boxes=True,
            include_points=True
        )
        
        pipeline_cfg = PipelineConfig(
            cluster=cluster_cfg,
            prompt=prompt_cfg
        )
        
        # åˆå§‹åŒ– Pipeline
        print("åˆå§‹åŒ– Pipeline...")
        pipeline = ZeroShotSegmentationPipeline(
            dinov3_cfg,
            sam2_cfg,
            pipeline_cfg,
            device=str(device),
            dtype=dtype
        )
        print("âœ… Pipeline åˆå§‹åŒ–æˆåŠŸ")
        
        # è¿è¡Œæ¨ç†
        print("è¿è¡Œæ¨ç†...")
        nms_config = {
            "enable_nms": True,
            "iou_threshold": 0.6,
            "objectness_weight": 0.5
        }
        
        result = pipeline.run(sample.image, nms_config=nms_config)
        print(f"âœ… æ¨ç†å®Œæˆ")
        print(f"   å€™é€‰åŒºåŸŸ: {len(result.proposals)}")
        print(f"   æœ€ç»ˆæ©ç : {len(result.masks)}")
        
        # ä¿å­˜ç»“æœ
        output_dir = Path("/media/pc/D/zhaochen/mono3d/mono3d/outputs/e2e_test_basic")
        ensure_directory(output_dir)
        
        if result.masks:
            combined = np.zeros_like(sample.image)
            for i, mask in enumerate(result.masks):
                color = np.array([
                    (i * 50) % 255,
                    (i * 80 + 60) % 255,
                    (i * 120 + 30) % 255
                ], dtype=np.uint8)
                combined[mask.astype(bool)] = color
            
            overlay = cv2.addWeighted(
                cv2.cvtColor(sample.image, cv2.COLOR_RGB2BGR), 0.5,
                cv2.cvtColor(combined, cv2.COLOR_RGB2BGR), 0.5, 0
            )
            cv2.imwrite(str(output_dir / "result.png"), overlay)
            print(f"âœ… ç»“æœå·²ä¿å­˜: {output_dir}/result.png")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_advanced_pipeline():
    """æµ‹è¯•é«˜çº§ Pipelineï¼ˆå¯ç”¨è¶…åƒç´  + å›¾èšç±»ï¼‰"""
    print("\n" + "=" * 80)
    print("æµ‹è¯• 2: é«˜çº§ Pipelineï¼ˆè¶…åƒç´  + å›¾èšç±»ï¼‰")
    print("=" * 80)
    
    try:
        # åŠ è½½å›¾åƒ
        image_path = "/media/pc/D/datasets/vkitti2/Scene01/clone/frames/rgb/Camera_0/rgb_00061.jpg"
        sample = load_image(image_path)
        print(f"âœ… å›¾åƒåŠ è½½: {sample.image.shape}")
        
        # é…ç½®
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        dtype = torch.float16 if device.type == "cuda" else torch.float32
        
        dinov3_cfg = Dinov3Config(
            repo_or_dir="/media/pc/D/zhaochen/mono3d/dinov3",
            model_name="dinov3_vith16plus",
            checkpoint_path="/media/pc/D/zhaochen/mono3d/dinov3/checkpoints/dinov3_vith16plus.pth",
            use_torch_hub=True,
            torchhub_source="local",
            output_layers=[4, 8, 12],
            layer_weights=[0.2, 0.3, 0.5],
            fusion_method="weighted_concat",
            enable_objectness=True
        )
        
        sam2_cfg = Sam2Config(
            backend="official",
            checkpoint_path="/media/pc/D/zhaochen/mono3d/sam2/checkpoints/sam2.1_hiera_large.pt",
            model_config="sam2.1/sam2.1_hiera_l"
        )
        
        cluster_cfg = ClusterConfig(
            num_clusters=6,
            min_region_area=400,
            use_objectness_filter=True
        )
        
        prompt_cfg = PromptConfig(
            include_boxes=True,
            include_points=True
        )
        
        superpixel_cfg = SuperpixelConfig(
            method="slic",
            n_segments=1000,
            compactness=10.0
        )
        
        graph_cluster_cfg = GraphClusterConfig(
            method="spectral",
            n_clusters=6
        )
        
        pipeline_cfg = PipelineConfig(
            cluster=cluster_cfg,
            prompt=prompt_cfg,
            use_superpixels=True,
            superpixel=superpixel_cfg,
            use_graph_clustering=True,
            graph_cluster=graph_cluster_cfg
        )
        
        # åˆå§‹åŒ– Pipeline
        print("åˆå§‹åŒ–é«˜çº§ Pipeline...")
        pipeline = ZeroShotSegmentationPipeline(
            dinov3_cfg,
            sam2_cfg,
            pipeline_cfg,
            device=str(device),
            dtype=dtype
        )
        print("âœ… Pipeline åˆå§‹åŒ–æˆåŠŸ")
        
        # è¿è¡Œæ¨ç†
        print("è¿è¡Œæ¨ç†...")
        nms_config = {
            "enable_nms": True,
            "iou_threshold": 0.6,
            "objectness_weight": 0.5
        }
        
        result = pipeline.run(sample.image, nms_config=nms_config)
        print(f"âœ… æ¨ç†å®Œæˆ")
        print(f"   å€™é€‰åŒºåŸŸ: {len(result.proposals)}")
        print(f"   æœ€ç»ˆæ©ç : {len(result.masks)}")
        
        # ä¿å­˜ç»“æœ
        output_dir = Path("/media/pc/D/zhaochen/mono3d/mono3d/outputs/e2e_test_advanced")
        ensure_directory(output_dir)
        
        if result.masks:
            combined = np.zeros_like(sample.image)
            for i, mask in enumerate(result.masks):
                color = np.array([
                    (i * 50) % 255,
                    (i * 80 + 60) % 255,
                    (i * 120 + 30) % 255
                ], dtype=np.uint8)
                combined[mask.astype(bool)] = color
            
            overlay = cv2.addWeighted(
                cv2.cvtColor(sample.image, cv2.COLOR_RGB2BGR), 0.5,
                cv2.cvtColor(combined, cv2.COLOR_RGB2BGR), 0.5, 0
            )
            cv2.imwrite(str(output_dir / "result.png"), overlay)
            
            # ä¿å­˜è¶…åƒç´ å¯è§†åŒ–
            if result.superpixel_labels is not None:
                from src.superpixel_helper import visualize_superpixels
                visualize_superpixels(
                    sample.image,
                    result.superpixel_labels,
                    str(output_dir / "superpixels.png")
                )
                print(f"âœ… è¶…åƒç´ å·²ä¿å­˜")
            
            print(f"âœ… ç»“æœå·²ä¿å­˜: {output_dir}/result.png")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_multilayer_fusion():
    """æµ‹è¯•å¤šå±‚ç‰¹å¾èåˆ"""
    print("\n" + "=" * 80)
    print("æµ‹è¯• 3: å¤šå±‚ç‰¹å¾èåˆ")
    print("=" * 80)
    
    try:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        dtype = torch.float16 if device.type == "cuda" else torch.float32
        
        dinov3_cfg = Dinov3Config(
            repo_or_dir="/media/pc/D/zhaochen/mono3d/dinov3",
            model_name="dinov3_vith16plus",
            checkpoint_path="/media/pc/D/zhaochen/mono3d/dinov3/checkpoints/dinov3_vith16plus.pth",
            use_torch_hub=True,
            torchhub_source="local",
            output_layers=[4, 8, 12],
            layer_weights=[0.2, 0.3, 0.5],
            fusion_method="weighted_concat"
        )
        
        extractor = DINOv3FeatureExtractor(dinov3_cfg, device, dtype)
        print("âœ… DINOv3 åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•å›¾åƒ
        image = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)
        
        # æå–ç‰¹å¾
        print("æå–å¤šå±‚ç‰¹å¾...")
        feats = extractor.extract_features(image)
        
        print(f"âœ… ç‰¹å¾æå–æˆåŠŸ")
        print(f"   Patch map: {feats['patch_map'].shape}")
        print(f"   Grid size: {feats['grid_size']}")
        
        if feats.get('objectness_map') is not None:
            print(f"   Objectness map: {feats['objectness_map'].shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "=" * 80)
    print("å¼€å§‹ç«¯åˆ°ç«¯æµ‹è¯•")
    print("=" * 80)
    
    results = {}
    
    # æµ‹è¯• 1: åŸºç¡€ Pipeline
    results['basic'] = test_basic_pipeline()
    
    # æµ‹è¯• 2: é«˜çº§ Pipeline
    results['advanced'] = test_advanced_pipeline()
    
    # æµ‹è¯• 3: å¤šå±‚èåˆ
    results['multilayer'] = test_multilayer_fusion()
    
    # æ€»ç»“
    print("\n" + "=" * 80)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 80)
    
    for test_name, passed in results.items():
        status = "âœ… PASS" if passed else "âŒ FAIL"
        print(f"  {test_name:<15}: {status}")
    
    all_passed = all(results.values())
    
    print("\n" + "=" * 80)
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
    print("=" * 80)
    
    return 0 if all_passed else 1


if __name__ == "__main__":
    sys.exit(main())