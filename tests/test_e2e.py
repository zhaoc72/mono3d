#!/usr/bin/env python3
"""
ç«¯åˆ°ç«¯æµ‹è¯•è„šæœ¬ - éªŒè¯å®Œæ•´ Pipeline
æµ‹è¯•æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½çš„é›†æˆï¼ŒåŒ…å«å¤šå±‚ç‰¹å¾èåˆå¯è§†åŒ–
"""

import sys
import yaml
import torch
import numpy as np
import cv2
from pathlib import Path
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

sys.path.insert(0, '/media/pc/D/zhaochen/mono3d/mono3d')

from src.dinov3_feature import DINOv3FeatureExtractor, Dinov3Config
from src.sam2_segmenter import SAM2Segmenter, Sam2Config
from src.inference_pipeline import ZeroShotSegmentationPipeline, PipelineConfig
from src.prompt_generator import ClusterConfig, PromptConfig
from src.superpixel_helper import SuperpixelConfig
from src.graph_clustering import GraphClusterConfig
from src.density_clustering import DensityClusterConfig
from src.crf_refinement import CRFConfig
from src.data_loader import load_image
from src.utils import to_torch_dtype, ensure_directory

print("=" * 80)
print("ç«¯åˆ°ç«¯ Pipeline æµ‹è¯•")
print("=" * 80)


def visualize_multilayer_features(image, feats, config, output_dir):
    """å¯è§†åŒ–å¤šå±‚ç‰¹å¾èåˆç»“æœ
    
    Args:
        image: åŸå§‹å›¾åƒ (H, W, 3)
        feats: ç‰¹å¾å­—å…¸
        config: DINOv3 é…ç½®
        output_dir: è¾“å‡ºç›®å½•
    """
    patch_map = feats['patch_map']  # (H, W, D)
    grid_h, grid_w, total_dim = patch_map.shape
    
    # 1. ä¿å­˜åŸå§‹å›¾åƒ
    plt.figure(figsize=(10, 6))
    plt.imshow(image)
    plt.title("Original Image", fontsize=16, fontweight='bold')
    plt.axis('off')
    plt.tight_layout()
    plt.savefig(output_dir / "0_original.png", dpi=150, bbox_inches='tight')
    plt.close()
    print("   âœ“ åŸå§‹å›¾åƒ")
    
    # 2. å¦‚æœæœ‰ objectness map,å…ˆå¯è§†åŒ–
    if feats.get('objectness_map') is not None:
        objectness = feats['objectness_map']
        
        plt.figure(figsize=(10, 6))
        plt.imshow(objectness, cmap='hot')
        plt.colorbar(label='Objectness Score', fraction=0.046)
        plt.title("Objectness Map", fontsize=16, fontweight='bold')
        plt.axis('off')
        plt.tight_layout()
        plt.savefig(output_dir / "1_objectness.png", dpi=150, bbox_inches='tight')
        plt.close()
        print("   âœ“ Objectness Map")
    
    # 3. å¯è§†åŒ–æ¯ä¸€å±‚çš„ç‰¹å¾ (ä½¿ç”¨ PCA é™ç»´åˆ° 3 ç»´ç”¨äº RGB å¯è§†åŒ–)
    layer_dim = 1280
    num_layers = len(config.output_layers)
    
    fig, axes = plt.subplots(1, num_layers, figsize=(6*num_layers, 6))
    if num_layers == 1:
        axes = [axes]
    
    for i, layer_idx in enumerate(config.output_layers):
        # æå–è¯¥å±‚çš„ç‰¹å¾
        start_idx = i * layer_dim
        end_idx = start_idx + layer_dim
        layer_feats = patch_map[:, :, start_idx:end_idx]  # (H, W, 1280)
        
        # PCA é™ç»´åˆ° 3D
        layer_feats_flat = layer_feats.reshape(-1, layer_dim)
        pca = PCA(n_components=3)
        pca_feats = pca.fit_transform(layer_feats_flat)
        
        # å½’ä¸€åŒ–åˆ° [0, 1]
        pca_feats = (pca_feats - pca_feats.min(axis=0)) / (pca_feats.max(axis=0) - pca_feats.min(axis=0) + 1e-8)
        pca_map = pca_feats.reshape(grid_h, grid_w, 3)
        
        # ä¸Šé‡‡æ ·åˆ°åŸå›¾å¤§å°
        pca_map_upsampled = cv2.resize(
            pca_map, 
            (image.shape[1], image.shape[0]), 
            interpolation=cv2.INTER_LINEAR
        )
        
        axes[i].imshow(pca_map_upsampled)
        axes[i].set_title(f"Layer {layer_idx}\n(weight={config.layer_weights[i]})", 
                         fontsize=14, fontweight='bold')
        axes[i].axis('off')
    
    plt.tight_layout()
    plt.savefig(output_dir / "2_individual_layers.png", dpi=150, bbox_inches='tight')
    plt.close()
    print(f"   âœ“ å„å±‚ç‰¹å¾ (Layers {config.output_layers})")
    
    # 4. å¯è§†åŒ–èåˆåçš„ç‰¹å¾
    fused_feats = patch_map.reshape(-1, total_dim)
    pca = PCA(n_components=3)
    pca_fused = pca.fit_transform(fused_feats)
    
    # å½’ä¸€åŒ–
    pca_fused = (pca_fused - pca_fused.min(axis=0)) / (pca_fused.max(axis=0) - pca_fused.min(axis=0) + 1e-8)
    pca_fused_map = pca_fused.reshape(grid_h, grid_w, 3)
    
    # ä¸Šé‡‡æ ·
    pca_fused_upsampled = cv2.resize(
        pca_fused_map,
        (image.shape[1], image.shape[0]),
        interpolation=cv2.INTER_LINEAR
    )
    
    plt.figure(figsize=(10, 6))
    plt.imshow(pca_fused_upsampled)
    plt.title(f"Fused Features ({config.fusion_method})\nDim: {total_dim} = {num_layers} Ã— 1280", 
             fontsize=16, fontweight='bold')
    plt.axis('off')
    plt.tight_layout()
    plt.savefig(output_dir / "3_fused_features.png", dpi=150, bbox_inches='tight')
    plt.close()
    print(f"   âœ“ èåˆç‰¹å¾")
    
    # 5. åˆ›å»ºå®Œæ•´å¯¹æ¯”å›¾
    fig = plt.figure(figsize=(20, 12))
    
    # åŸå›¾
    ax1 = plt.subplot(2, 3, 1)
    ax1.imshow(image)
    ax1.set_title("Original Image", fontsize=14, fontweight='bold')
    ax1.axis('off')
    
    # Objectness (å¦‚æœæœ‰)
    if feats.get('objectness_map') is not None:
        ax2 = plt.subplot(2, 3, 2)
        im = ax2.imshow(feats['objectness_map'], cmap='hot')
        ax2.set_title("Objectness Map", fontsize=14, fontweight='bold')
        ax2.axis('off')
        plt.colorbar(im, ax=ax2, fraction=0.046)
    
    # å„å±‚ç‰¹å¾
    for i, layer_idx in enumerate(config.output_layers):
        ax = plt.subplot(2, 3, 3 + i)
        
        start_idx = i * layer_dim
        end_idx = start_idx + layer_dim
        layer_feats = patch_map[:, :, start_idx:end_idx]
        
        layer_feats_flat = layer_feats.reshape(-1, layer_dim)
        pca = PCA(n_components=3)
        pca_feats = pca.fit_transform(layer_feats_flat)
        pca_feats = (pca_feats - pca_feats.min(axis=0)) / (pca_feats.max(axis=0) - pca_feats.min(axis=0) + 1e-8)
        pca_map = pca_feats.reshape(grid_h, grid_w, 3)
        pca_map_upsampled = cv2.resize(pca_map, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_LINEAR)
        
        ax.imshow(pca_map_upsampled)
        ax.set_title(f"Layer {layer_idx} (w={config.layer_weights[i]})", fontsize=12, fontweight='bold')
        ax.axis('off')
    
    # èåˆç»“æœ
    ax_fused = plt.subplot(2, 3, 6)
    ax_fused.imshow(pca_fused_upsampled)
    ax_fused.set_title(f"Fused Features\n{config.fusion_method} | Dim={total_dim}", 
                       fontsize=12, fontweight='bold')
    ax_fused.axis('off')
    
    plt.suptitle("Multi-Layer Feature Fusion Visualization", fontsize=16, fontweight='bold', y=0.98)
    plt.tight_layout()
    plt.savefig(output_dir / "4_complete_comparison.png", dpi=150, bbox_inches='tight')
    plt.close()
    print(f"   âœ“ å®Œæ•´å¯¹æ¯”å›¾")
    
    # 6. ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    # å„å±‚ç‰¹å¾çš„æ–¹å·®è§£é‡Šç‡
    ax1 = axes[0, 0]
    variance_ratios = []
    for i in range(num_layers):
        start_idx = i * layer_dim
        end_idx = start_idx + layer_dim
        layer_feats = patch_map[:, :, start_idx:end_idx].reshape(-1, layer_dim)
        pca_temp = PCA(n_components=10)
        pca_temp.fit(layer_feats)
        variance_ratios.append(pca_temp.explained_variance_ratio_[:5])
    
    x = np.arange(5)
    width = 0.25
    for i, (layer_idx, ratios) in enumerate(zip(config.output_layers, variance_ratios)):
        ax1.bar(x + i*width, ratios, width, label=f'Layer {layer_idx}')
    
    ax1.set_xlabel('Principal Component', fontsize=12)
    ax1.set_ylabel('Explained Variance Ratio', fontsize=12)
    ax1.set_title('Feature Variance by Layer (Top 5 PCs)', fontsize=14, fontweight='bold')
    ax1.set_xticks(x + width)
    ax1.set_xticklabels([f'PC{i+1}' for i in range(5)])
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # èåˆç‰¹å¾çš„æ–¹å·®è§£é‡Šç‡
    ax2 = axes[0, 1]
    pca_fused_full = PCA(n_components=min(20, total_dim))
    pca_fused_full.fit(fused_feats)
    n_components = len(pca_fused_full.explained_variance_ratio_)
    ax2.plot(range(1, n_components + 1), pca_fused_full.explained_variance_ratio_, 'o-', linewidth=2, markersize=6)
    ax2.set_xlabel('Principal Component', fontsize=12)
    ax2.set_ylabel('Explained Variance Ratio', fontsize=12)
    ax2.set_title(f'Fused Features Variance (Top {n_components} PCs)', fontsize=14, fontweight='bold')
    ax2.grid(True, alpha=0.3)
    
    # ç‰¹å¾ç»´åº¦åˆ†å¸ƒ
    ax3 = axes[1, 0]
    layer_labels = [f'Layer {idx}' for idx in config.output_layers]
    layer_dims = [layer_dim] * num_layers
    colors = plt.cm.viridis(np.linspace(0, 1, num_layers))
    bars = ax3.bar(layer_labels, layer_dims, color=colors, alpha=0.7, edgecolor='black', linewidth=2)
    ax3.axhline(y=total_dim, color='r', linestyle='--', linewidth=2, label=f'Total: {total_dim}')
    ax3.set_ylabel('Feature Dimension', fontsize=12)
    ax3.set_title('Feature Dimensions by Layer', fontsize=14, fontweight='bold')
    ax3.legend(fontsize=11)
    ax3.grid(True, alpha=0.3, axis='y')
    
    # åœ¨æ¯ä¸ªæŸ±å­ä¸Šæ·»åŠ æ•°å€¼
    for bar in bars:
        height = bar.get_height()
        ax3.text(bar.get_x() + bar.get_width()/2., height,
                f'{int(height)}', ha='center', va='bottom', fontsize=11, fontweight='bold')
    
    # æƒé‡åˆ†å¸ƒ
    ax4 = axes[1, 1]
    wedges, texts, autotexts = ax4.pie(
        config.layer_weights, 
        labels=layer_labels, 
        autopct='%1.1f%%', 
        colors=colors, 
        startangle=90,
        textprops={'fontsize': 12, 'fontweight': 'bold'}
    )
    ax4.set_title('Layer Weights Distribution', fontsize=14, fontweight='bold')
    
    plt.suptitle('Feature Statistics & Analysis', fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.savefig(output_dir / "5_statistics.png", dpi=150, bbox_inches='tight')
    plt.close()
    print(f"   âœ“ ç»Ÿè®¡åˆ†æå›¾")
    
    # 7. ç”Ÿæˆ README è¯´æ˜æ–‡ä»¶
    readme_content = f"""# å¤šå±‚ç‰¹å¾èåˆå¯è§†åŒ–ç»“æœ

## é…ç½®ä¿¡æ¯
- **æ¨¡å‹**: {config.model_name}
- **èåˆå±‚**: {config.output_layers}
- **å±‚æƒé‡**: {config.layer_weights}
- **èåˆæ–¹æ³•**: {config.fusion_method}
- **æ€»ç‰¹å¾ç»´åº¦**: {total_dim} ({num_layers} Ã— 1280)

## æ–‡ä»¶è¯´æ˜

### 0_original.png
åŸå§‹è¾“å…¥å›¾åƒ

### 1_objectness.png
Objectness Map - æ˜¾ç¤ºæ¨¡å‹å¯¹æ¯ä¸ªåŒºåŸŸæ˜¯å¦ä¸ºç‰©ä½“çš„ç½®ä¿¡åº¦

### 2_individual_layers.png
å„å±‚ç‹¬ç«‹ç‰¹å¾å¯è§†åŒ– (ä½¿ç”¨PCAé™ç»´åˆ°RGB)
- Layer {config.output_layers[0]}: ä½å±‚ç‰¹å¾,å…³æ³¨è¾¹ç¼˜å’Œçº¹ç†
- Layer {config.output_layers[1] if len(config.output_layers) > 1 else 'N/A'}: ä¸­å±‚ç‰¹å¾,å…³æ³¨å±€éƒ¨æ¨¡å¼
- Layer {config.output_layers[2] if len(config.output_layers) > 2 else 'N/A'}: é«˜å±‚ç‰¹å¾,å…³æ³¨è¯­ä¹‰ä¿¡æ¯

### 3_fused_features.png
èåˆåçš„ç‰¹å¾ - æ•´åˆäº†å¤šå±‚ä¿¡æ¯çš„ç»¼åˆè¡¨ç¤º

### 4_complete_comparison.png
å®Œæ•´å¯¹æ¯”å›¾ - å±•ç¤ºä»åŸå›¾åˆ°å„å±‚ç‰¹å¾å†åˆ°èåˆç‰¹å¾çš„å®Œæ•´æµç¨‹

### 5_statistics.png
ç»Ÿè®¡åˆ†æå›¾,åŒ…å«:
- å„å±‚ç‰¹å¾æ–¹å·®åˆ†æ (å‰5ä¸ªä¸»æˆåˆ†)
- èåˆç‰¹å¾æ–¹å·®åˆ†æ (å‰20ä¸ªä¸»æˆåˆ†)
- å„å±‚ç‰¹å¾ç»´åº¦åˆ†å¸ƒ
- å±‚æƒé‡åˆ†å¸ƒ

## å…³é”®å‘ç°
1. ç‰¹å¾ç»´åº¦ä»å•å±‚çš„1280æ‰©å±•åˆ°{total_dim}
2. ä¸åŒå±‚æ•è·ä¸åŒçº§åˆ«çš„è§†è§‰ç‰¹å¾
3. æƒé‡èåˆå¹³è¡¡äº†å„å±‚çš„è´¡çŒ®

## ç”Ÿæˆæ—¶é—´
{Path(output_dir).name}
"""
    
    with open(output_dir / "README.md", "w", encoding="utf-8") as f:
        f.write(readme_content)
    print(f"   âœ“ README è¯´æ˜æ–‡ä»¶")


def test_basic_pipeline():
    """æµ‹è¯•åŸºç¡€ Pipelineï¼ˆæœ€ç®€é…ç½®ï¼‰"""
    print("\n" + "=" * 80)
    print("æµ‹è¯• 1: åŸºç¡€ Pipeline")
    print("=" * 80)
    
    try:
        # åŠ è½½å›¾åƒ
        image_path = "/media/pc/D/datasets/vkitti2/Scene01/clone/frames/rgb/Camera_0/rgb_00061.jpg"
        sample = load_image(image_path)
        print(f"âœ… å›¾åƒåŠ è½½: {sample.image.shape}")
        
        # é…ç½®
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        dtype = torch.float16 if device.type == "cuda" else torch.float32
        
        dinov3_cfg = Dinov3Config(
            repo_or_dir="/media/pc/D/zhaochen/mono3d/dinov3",
            model_name="dinov3_vith16plus",
            checkpoint_path="/media/pc/D/zhaochen/mono3d/dinov3/checkpoints/dinov3_vith16plus.pth",
            use_torch_hub=True,
            torchhub_source="local",
            enable_objectness=True
        )
        
        sam2_cfg = Sam2Config(
            backend="official",
            checkpoint_path="/media/pc/D/zhaochen/mono3d/sam2/checkpoints/sam2.1_hiera_large.pt",
            model_config="sam2.1/sam2.1_hiera_l"
        )
        
        cluster_cfg = ClusterConfig(
            num_clusters=6,
            min_region_area=400,
            use_objectness_filter=True
        )
        
        prompt_cfg = PromptConfig(
            include_boxes=True,
            include_points=True
        )
        
        pipeline_cfg = PipelineConfig(
            cluster=cluster_cfg,
            prompt=prompt_cfg
        )
        
        # åˆå§‹åŒ– Pipeline
        print("åˆå§‹åŒ– Pipeline...")
        pipeline = ZeroShotSegmentationPipeline(
            dinov3_cfg,
            sam2_cfg,
            pipeline_cfg,
            device=str(device),
            dtype=dtype
        )
        print("âœ… Pipeline åˆå§‹åŒ–æˆåŠŸ")
        
        # è¿è¡Œæ¨ç†
        print("è¿è¡Œæ¨ç†...")
        nms_config = {
            "enable_nms": True,
            "iou_threshold": 0.6,
            "objectness_weight": 0.5
        }
        
        result = pipeline.run(sample.image, nms_config=nms_config)
        print(f"âœ… æ¨ç†å®Œæˆ")
        print(f"   å€™é€‰åŒºåŸŸ: {len(result.proposals)}")
        print(f"   æœ€ç»ˆæ©ç : {len(result.masks)}")
        
        # ä¿å­˜ç»“æœ
        output_dir = Path("/media/pc/D/zhaochen/mono3d/mono3d/outputs/e2e_test_basic")
        ensure_directory(output_dir)
        
        if result.masks:
            combined = np.zeros_like(sample.image)
            for i, mask in enumerate(result.masks):
                color = np.array([
                    (i * 50) % 255,
                    (i * 80 + 60) % 255,
                    (i * 120 + 30) % 255
                ], dtype=np.uint8)
                combined[mask.astype(bool)] = color
            
            overlay = cv2.addWeighted(
                cv2.cvtColor(sample.image, cv2.COLOR_RGB2BGR), 0.5,
                cv2.cvtColor(combined, cv2.COLOR_RGB2BGR), 0.5, 0
            )
            cv2.imwrite(str(output_dir / "result.png"), overlay)
            print(f"âœ… ç»“æœå·²ä¿å­˜: {output_dir}/result.png")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_advanced_pipeline():
    """æµ‹è¯•é«˜çº§ Pipelineï¼ˆå¯ç”¨è¶…åƒç´  + å›¾èšç±»ï¼‰"""
    print("\n" + "=" * 80)
    print("æµ‹è¯• 2: é«˜çº§ Pipelineï¼ˆè¶…åƒç´  + å›¾èšç±»ï¼‰")
    print("=" * 80)
    
    try:
        # åŠ è½½å›¾åƒ
        image_path = "/media/pc/D/datasets/vkitti2/Scene01/clone/frames/rgb/Camera_0/rgb_00061.jpg"
        sample = load_image(image_path)
        print(f"âœ… å›¾åƒåŠ è½½: {sample.image.shape}")
        
        # é…ç½®
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        dtype = torch.float16 if device.type == "cuda" else torch.float32
        
        dinov3_cfg = Dinov3Config(
            repo_or_dir="/media/pc/D/zhaochen/mono3d/dinov3",
            model_name="dinov3_vith16plus",
            checkpoint_path="/media/pc/D/zhaochen/mono3d/dinov3/checkpoints/dinov3_vith16plus.pth",
            use_torch_hub=True,
            torchhub_source="local",
            output_layers=[4, 8, 12],
            layer_weights=[0.2, 0.3, 0.5],
            fusion_method="weighted_concat",
            enable_objectness=True
        )
        
        sam2_cfg = Sam2Config(
            backend="official",
            checkpoint_path="/media/pc/D/zhaochen/mono3d/sam2/checkpoints/sam2.1_hiera_large.pt",
            model_config="sam2.1/sam2.1_hiera_l"
        )
        
        cluster_cfg = ClusterConfig(
            num_clusters=6,
            min_region_area=400,
            use_objectness_filter=True
        )
        
        prompt_cfg = PromptConfig(
            include_boxes=True,
            include_points=True
        )
        
        superpixel_cfg = SuperpixelConfig(
            method="slic",
            n_segments=1000,
            compactness=10.0
        )
        
        graph_cluster_cfg = GraphClusterConfig(
            method="spectral",
            n_clusters=6
        )
        
        pipeline_cfg = PipelineConfig(
            cluster=cluster_cfg,
            prompt=prompt_cfg,
            use_superpixels=True,
            superpixel=superpixel_cfg,
            use_graph_clustering=True,
            graph_cluster=graph_cluster_cfg
        )
        
        # åˆå§‹åŒ– Pipeline
        print("åˆå§‹åŒ–é«˜çº§ Pipeline...")
        pipeline = ZeroShotSegmentationPipeline(
            dinov3_cfg,
            sam2_cfg,
            pipeline_cfg,
            device=str(device),
            dtype=dtype
        )
        print("âœ… Pipeline åˆå§‹åŒ–æˆåŠŸ")
        
        # è¿è¡Œæ¨ç†
        print("è¿è¡Œæ¨ç†...")
        nms_config = {
            "enable_nms": True,
            "iou_threshold": 0.6,
            "objectness_weight": 0.5
        }
        
        result = pipeline.run(sample.image, nms_config=nms_config)
        print(f"âœ… æ¨ç†å®Œæˆ")
        print(f"   å€™é€‰åŒºåŸŸ: {len(result.proposals)}")
        print(f"   æœ€ç»ˆæ©ç : {len(result.masks)}")
        
        # ä¿å­˜ç»“æœ
        output_dir = Path("/media/pc/D/zhaochen/mono3d/mono3d/outputs/e2e_test_advanced")
        ensure_directory(output_dir)
        
        if result.masks:
            combined = np.zeros_like(sample.image)
            for i, mask in enumerate(result.masks):
                color = np.array([
                    (i * 50) % 255,
                    (i * 80 + 60) % 255,
                    (i * 120 + 30) % 255
                ], dtype=np.uint8)
                combined[mask.astype(bool)] = color
            
            overlay = cv2.addWeighted(
                cv2.cvtColor(sample.image, cv2.COLOR_RGB2BGR), 0.5,
                cv2.cvtColor(combined, cv2.COLOR_RGB2BGR), 0.5, 0
            )
            cv2.imwrite(str(output_dir / "result.png"), overlay)
            
            # ä¿å­˜è¶…åƒç´ å¯è§†åŒ–
            if result.superpixel_labels is not None:
                from src.superpixel_helper import visualize_superpixels
                visualize_superpixels(
                    sample.image,
                    result.superpixel_labels,
                    str(output_dir / "superpixels.png")
                )
                print(f"âœ… è¶…åƒç´ å·²ä¿å­˜")
            
            print(f"âœ… ç»“æœå·²ä¿å­˜: {output_dir}/result.png")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_multilayer_fusion():
    """æµ‹è¯•å¤šå±‚ç‰¹å¾èåˆ"""
    print("\n" + "=" * 80)
    print("æµ‹è¯• 3: å¤šå±‚ç‰¹å¾èåˆ")
    print("=" * 80)
    
    try:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        dtype = torch.float16 if device.type == "cuda" else torch.float32
        
        # åŠ è½½çœŸå®å›¾åƒç”¨äºå¯è§†åŒ–
        image_path = "/media/pc/D/datasets/vkitti2/Scene01/clone/frames/rgb/Camera_0/rgb_00061.jpg"
        sample = load_image(image_path)
        image = sample.image
        print(f"âœ… å›¾åƒåŠ è½½: {image.shape}")
        
        dinov3_cfg = Dinov3Config(
            repo_or_dir="/media/pc/D/zhaochen/mono3d/dinov3",
            model_name="dinov3_vith16plus",
            checkpoint_path="/media/pc/D/zhaochen/mono3d/dinov3/checkpoints/dinov3_vith16plus.pth",
            use_torch_hub=True,
            torchhub_source="local",
            output_layers=[4, 8, 12],
            layer_weights=[0.2, 0.3, 0.5],
            fusion_method="weighted_concat",
            enable_objectness=True
        )
        
        extractor = DINOv3FeatureExtractor(dinov3_cfg, device, dtype)
        print("âœ… DINOv3 åˆå§‹åŒ–æˆåŠŸ")
        
        # æå–ç‰¹å¾
        print("æå–å¤šå±‚ç‰¹å¾...")
        feats = extractor.extract_features(image)
        
        print(f"âœ… ç‰¹å¾æå–æˆåŠŸ")
        print(f"   Patch map: {feats['patch_map'].shape}")
        print(f"   Grid size: {feats['grid_size']}")
        
        # è¯¦ç»†çš„èåˆéªŒè¯
        expected_dim = 1280 * len(dinov3_cfg.output_layers)
        actual_dim = feats['patch_map'].shape[-1]
        
        print(f"\nğŸ“Š å¤šå±‚èåˆéªŒè¯:")
        print(f"   é…ç½®å±‚æ•°: {len(dinov3_cfg.output_layers)} (layers {dinov3_cfg.output_layers})")
        print(f"   å•å±‚ç‰¹å¾ç»´åº¦: 1280")
        print(f"   æœŸæœ›èåˆç»´åº¦: {expected_dim}")
        print(f"   å®é™…èåˆç»´åº¦: {actual_dim}")
        print(f"   èåˆæ–¹æ³•: {dinov3_cfg.fusion_method}")
        print(f"   å±‚æƒé‡: {dinov3_cfg.layer_weights}")
        
        if actual_dim == expected_dim:
            print(f"   âœ… ç»´åº¦åŒ¹é…! å¤šå±‚èåˆæˆåŠŸ!")
        else:
            print(f"   âš ï¸  ç»´åº¦ä¸åŒ¹é…")
        
        if feats.get('objectness_map') is not None:
            print(f"   Objectness map: {feats['objectness_map'].shape}")
        
        # å¯è§†åŒ–å¤šå±‚ç‰¹å¾
        print("\nğŸ¨ ç”Ÿæˆå¯è§†åŒ–...")
        output_dir = Path("/media/pc/D/zhaochen/mono3d/mono3d/outputs/e2e_test_multilayer")
        ensure_directory(output_dir)
        
        visualize_multilayer_features(
            image, 
            feats, 
            dinov3_cfg,
            output_dir
        )
        
        print(f"\nâœ… æ‰€æœ‰å¯è§†åŒ–å·²ä¿å­˜åˆ°: {output_dir}")
        print(f"   åŒ…å« 7 ä¸ªæ–‡ä»¶:")
        print(f"   - 0_original.png: åŸå§‹å›¾åƒ")
        print(f"   - 1_objectness.png: Objectness Map")
        print(f"   - 2_individual_layers.png: å„å±‚ç‹¬ç«‹ç‰¹å¾")
        print(f"   - 3_fused_features.png: èåˆç‰¹å¾")
        print(f"   - 4_complete_comparison.png: å®Œæ•´å¯¹æ¯”")
        print(f"   - 5_statistics.png: ç»Ÿè®¡åˆ†æ")
        print(f"   - README.md: è¯¦ç»†è¯´æ˜")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "=" * 80)
    print("å¼€å§‹ç«¯åˆ°ç«¯æµ‹è¯•")
    print("=" * 80)
    
    results = {}
    
    # æµ‹è¯• 1: åŸºç¡€ Pipeline
    results['basic'] = test_basic_pipeline()
    
    # æµ‹è¯• 2: é«˜çº§ Pipeline
    results['advanced'] = test_advanced_pipeline()
    
    # æµ‹è¯• 3: å¤šå±‚èåˆ
    results['multilayer'] = test_multilayer_fusion()
    
    # æ€»ç»“
    print("\n" + "=" * 80)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 80)
    
    for test_name, passed in results.items():
        status = "âœ… PASS" if passed else "âŒ FAIL"
        print(f"  {test_name:<15}: {status}")
    
    all_passed = all(results.values())
    
    print("\n" + "=" * 80)
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
    print("=" * 80)
    
    return 0 if all_passed else 1


if __name__ == "__main__":
    sys.exit(main())