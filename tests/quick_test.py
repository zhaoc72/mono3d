#!/usr/bin/env python3
"""
ç‹¬ç«‹çš„å¯è§†åŒ–å¯¹æ¯”è„šæœ¬
ä¸ä¾èµ–é¡¹ç›®å†…éƒ¨æ¨¡å—ï¼Œå¯ä»¥ç›´æ¥è¿è¡Œ

å¯¹æ¯”ä¸‰ç§çƒ­å›¾ç”Ÿæˆæ–¹æ³•ï¼š
1. objectness (ç‰©ä½“æ€§)
2. combined (ç»„åˆ)  
3. attention (æ³¨æ„åŠ›)
"""

import sys
import torch
import numpy as np
import cv2
from pathlib import Path
from dataclasses import dataclass
from typing import List, Tuple, Optional
from scipy import ndimage
from sklearn.cluster import KMeans
import torch.nn.functional as F

# æ·»åŠ æ”¹è¿›æå–å™¨è·¯å¾„
sys.path.insert(0, '/home/claude')
from improved_dinov3_extractor import ImprovedDINOv3Extractor


@dataclass
class BoundingBox:
    """è¾¹ç•Œæ¡†"""
    x_min: int
    y_min: int
    x_max: int
    y_max: int
    
    def to_list(self) -> List[int]:
        return [self.x_min, self.y_min, self.x_max, self.y_max]
    
    @property
    def area(self) -> int:
        return (self.x_max - self.x_min) * (self.y_max - self.y_min)
    
    @property
    def centroid(self) -> Tuple[int, int]:
        cx = (self.x_min + self.x_max) // 2
        cy = (self.y_min + self.y_max) // 2
        return (cx, cy)


def heatmap_to_boxes(
    heatmap: np.ndarray,
    percentile: float = 65.0,
    smoothing_kernel: int = 10,
    min_component_area: int = 4000
) -> List[BoundingBox]:
    """ä»çƒ­å›¾ç”Ÿæˆå€™é€‰æ¡†
    
    Args:
        heatmap: çƒ­å›¾ (H, W)
        percentile: é˜ˆå€¼ç™¾åˆ†ä½
        smoothing_kernel: å¹³æ»‘æ ¸å¤§å°
        min_component_area: æœ€å°è¿é€šåŒºåŸŸé¢ç§¯
    
    Returns:
        å€™é€‰æ¡†åˆ—è¡¨
    """
    # 1. å½’ä¸€åŒ–
    heatmap_norm = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + 1e-8)
    
    # 2. å¹³æ»‘
    if smoothing_kernel > 0:
        # ç¡®ä¿æ ¸å¤§å°æ˜¯å¥‡æ•°
        kernel_size = smoothing_kernel if smoothing_kernel % 2 == 1 else smoothing_kernel + 1
        heatmap_norm = cv2.GaussianBlur(
            heatmap_norm, 
            (kernel_size, kernel_size), 
            0
        )
    
    # 3. é˜ˆå€¼åŒ–
    threshold = np.percentile(heatmap_norm, percentile)
    binary_mask = (heatmap_norm > threshold).astype(np.uint8)
    
    # 4. å½¢æ€å­¦æ“ä½œ
    kernel = np.ones((3, 3), np.uint8)
    binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel, iterations=2)
    binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel, iterations=1)
    
    # 5. è¿é€šç»„ä»¶åˆ†æ
    labeled_array, num_features = ndimage.label(binary_mask)
    
    boxes = []
    for label_id in range(1, num_features + 1):
        component_mask = (labeled_array == label_id)
        area = component_mask.sum()
        
        if area < min_component_area:
            continue
        
        # è·å–è¾¹ç•Œæ¡†
        coords = np.where(component_mask)
        y_min, y_max = coords[0].min(), coords[0].max()
        x_min, x_max = coords[1].min(), coords[1].max()
        
        boxes.append(BoundingBox(
            x_min=int(x_min),
            y_min=int(y_min),
            x_max=int(x_max),
            y_max=int(y_max)
        ))
    
    return boxes


def load_sam2_model(device: torch.device):
    """åŠ è½½ SAM2 æ¨¡å‹"""
    try:
        from sam2.build_sam import build_sam2
        from sam2.sam2_image_predictor import SAM2ImagePredictor
        
        checkpoint = "/media/pc/D/zhaochen/mono3d/sam2/checkpoints/sam2.1_hiera_large.pt"
        model_cfg = "configs/sam2.1/sam2.1_hiera_l.yaml"
        
        sam2_model = build_sam2(model_cfg, checkpoint, device=device)
        predictor = SAM2ImagePredictor(sam2_model)
        
        return predictor
    except Exception as e:
        print(f"âš ï¸  SAM2 åŠ è½½å¤±è´¥: {e}")
        print(f"   å°†ä½¿ç”¨æ¨¡æ‹Ÿåˆ†å‰²ç»“æœ")
        return None


def segment_with_sam2(
    predictor,
    image: np.ndarray,
    boxes: List[BoundingBox],
    device: torch.device
) -> List[np.ndarray]:
    """ä½¿ç”¨ SAM2 è¿›è¡Œåˆ†å‰²"""
    if predictor is None:
        # æ¨¡æ‹Ÿåˆ†å‰²ç»“æœ
        print("   ä½¿ç”¨æ¨¡æ‹Ÿåˆ†å‰²...")
        masks = []
        for box in boxes:
            mask = np.zeros(image.shape[:2], dtype=np.uint8)
            mask[box.y_min:box.y_max, box.x_min:box.x_max] = 1
            masks.append(mask)
        return masks
    
    predictor.set_image(image)
    
    masks = []
    for box in boxes:
        box_array = np.array([box.to_list()])
        
        mask, score, logit = predictor.predict(
            point_coords=None,
            point_labels=None,
            box=box_array,
            multimask_output=False
        )
        
        masks.append(mask[0].astype(np.uint8))
    
    return masks


def save_heatmap(heatmap, image, output_dir):
    """ä¿å­˜çƒ­å›¾å¯è§†åŒ–"""
    output_dir = Path(output_dir)
    output_dir.mkdir(exist_ok=True, parents=True)
    
    # å½’ä¸€åŒ–
    heatmap_norm = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + 1e-8)
    
    # 1. çº¯çƒ­å›¾
    heatmap_vis = (heatmap_norm * 255).astype(np.uint8)
    heatmap_colored = cv2.applyColorMap(heatmap_vis, cv2.COLORMAP_JET)
    cv2.imwrite(str(output_dir / "01_heatmap.jpg"), heatmap_colored)
    
    # 2. çƒ­å›¾å åŠ 
    overlay = cv2.addWeighted(
        cv2.cvtColor(image, cv2.COLOR_RGB2BGR), 0.6,
        heatmap_colored, 0.4, 0
    )
    cv2.imwrite(str(output_dir / "02_heatmap_overlay.jpg"), overlay)
    
    # 3. ç»Ÿè®¡
    with open(output_dir / "heatmap_stats.txt", 'w') as f:
        f.write("=== çƒ­å›¾ç»Ÿè®¡ ===\n")
        f.write(f"æœ€å°å€¼: {heatmap.min():.4f}\n")
        f.write(f"æœ€å¤§å€¼: {heatmap.max():.4f}\n")
        f.write(f"å‡å€¼:   {heatmap.mean():.4f}\n")
        f.write(f"æ ‡å‡†å·®: {heatmap.std():.4f}\n")
        f.write(f"ä¸­ä½æ•°: {np.median(heatmap):.4f}\n")
    
    return heatmap_colored, {
        'min': float(heatmap.min()),
        'max': float(heatmap.max()),
        'mean': float(heatmap.mean()),
        'std': float(heatmap.std())
    }


def save_boxes(image, boxes, output_dir):
    """ä¿å­˜å€™é€‰æ¡†å¯è§†åŒ–"""
    output_dir = Path(output_dir)
    
    if not boxes:
        img_blank = image.copy()
        cv2.putText(img_blank, "No boxes", (50, 50),
                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)
        cv2.imwrite(str(output_dir / "03_boxes.jpg"),
                   cv2.cvtColor(img_blank, cv2.COLOR_RGB2BGR))
        return
    
    # ç®€æ´ç‰ˆ
    img_simple = image.copy()
    for box in boxes:
        cv2.rectangle(img_simple, 
                     (box.x_min, box.y_min), 
                     (box.x_max, box.y_max), 
                     (0, 255, 0), 2)
    cv2.imwrite(str(output_dir / "03_boxes.jpg"),
               cv2.cvtColor(img_simple, cv2.COLOR_RGB2BGR))
    
    # è¯¦ç»†ç‰ˆ
    img_detail = image.copy()
    for i, box in enumerate(boxes):
        cv2.rectangle(img_detail,
                     (box.x_min, box.y_min),
                     (box.x_max, box.y_max),
                     (0, 255, 0), 2)
        cv2.putText(img_detail, f"#{i}", 
                   (box.x_min, box.y_min-10),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        cv2.putText(img_detail, f"{box.area:.0f}px",
                   (box.x_min, box.y_max+20),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 200, 0), 1)
    cv2.imwrite(str(output_dir / "04_boxes_detail.jpg"),
               cv2.cvtColor(img_detail, cv2.COLOR_RGB2BGR))
    
    # ç»Ÿè®¡
    with open(output_dir / "boxes_stats.txt", 'w') as f:
        f.write("=== å€™é€‰æ¡†ç»Ÿè®¡ ===\n")
        f.write(f"æ€»æ•°: {len(boxes)}\n\n")
        f.write("è¯¦ç»†ä¿¡æ¯:\n")
        for i, box in enumerate(boxes):
            f.write(f"Box {i}: [{box.x_min:4d}, {box.y_min:4d}, "
                   f"{box.x_max:4d}, {box.y_max:4d}], area={box.area:7.0f}\n")


def save_masks(image, masks, area_threshold, output_dir):
    """ä¿å­˜åˆ†å‰²æ©ç å¯è§†åŒ–"""
    output_dir = Path(output_dir)
    
    if not masks:
        img_blank = image.copy()
        cv2.putText(img_blank, "No masks", (50, 50),
                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)
        cv2.imwrite(str(output_dir / "05_masks.jpg"),
                   cv2.cvtColor(img_blank, cv2.COLOR_RGB2BGR))
        return []
    
    # å½©è‰²ç»„åˆ
    combined = np.zeros_like(image)
    valid_masks = []
    
    for i, mask in enumerate(masks):
        area = mask.sum()
        if area >= area_threshold:
            valid_masks.append((i, mask, area))
            color = np.array([
                (i * 50) % 255,
                (i * 80 + 60) % 255,
                (i * 120 + 30) % 255
            ], dtype=np.uint8)
            combined[mask.astype(bool)] = color
    
    cv2.imwrite(str(output_dir / "05_masks.jpg"),
               cv2.cvtColor(combined, cv2.COLOR_RGB2BGR))
    
    # å åŠ 
    if len(valid_masks) > 0:
        overlay = cv2.addWeighted(
            cv2.cvtColor(image, cv2.COLOR_RGB2BGR), 0.5,
            cv2.cvtColor(combined, cv2.COLOR_RGB2BGR), 0.5, 0
        )
        cv2.imwrite(str(output_dir / "06_masks_overlay.jpg"), overlay)
    
    # å•ç‹¬æ©ç 
    individual_dir = output_dir / "07_individual_masks"
    individual_dir.mkdir(exist_ok=True)
    for idx, (i, mask, area) in enumerate(valid_masks[:5]):
        mask_vis = (mask.astype(np.uint8) * 255)
        cv2.imwrite(str(individual_dir / f"mask_{i:02d}_area_{area:.0f}.jpg"), 
                   mask_vis)
    
    # ç»Ÿè®¡
    with open(output_dir / "masks_stats.txt", 'w') as f:
        f.write("=== åˆ†å‰²æ©ç ç»Ÿè®¡ ===\n")
        f.write(f"æ€»æ©ç æ•°: {len(masks)}\n")
        f.write(f"æœ‰æ•ˆæ©ç æ•°: {len(valid_masks)}\n")
        if len(masks) > 0:
            f.write(f"æœ‰æ•ˆç‡: {len(valid_masks)/len(masks)*100:.1f}%\n")
        f.write(f"é¢ç§¯é˜ˆå€¼: {area_threshold}\n\n")
        f.write("æ‰€æœ‰æ©ç è¯¦æƒ…:\n")
        for i, mask in enumerate(masks):
            area = mask.sum()
            passed = "âœ…" if area >= area_threshold else "âŒ"
            ratio = area / (image.shape[0] * image.shape[1]) * 100
            f.write(f"Mask {i}: area={area:8.0f}, ratio={ratio:5.2f}%, {passed}\n")
    
    return valid_masks


def create_comparison_grid(methods_data, output_path):
    """åˆ›å»ºå¯¹æ¯”ç½‘æ ¼å›¾"""
    print(f"\nåˆ›å»ºå¯¹æ¯”ç½‘æ ¼å›¾...")
    
    cell_h, cell_w = 300, 400
    margin = 10
    label_h = 40
    
    method_labels = {
        'objectness': 'ç‰©ä½“æ€§ (æ¨è)',
        'combined': 'ç»„åˆ (æ¨è)',
        'attention': 'Attention (å½“å‰)'
    }
    
    col_labels = ['åŸå›¾', 'çƒ­å›¾', 'Boxes', 'æ©ç ']
    
    n_methods = len(methods_data)
    n_cols = len(col_labels)
    
    canvas_h = label_h + n_methods * (cell_h + margin) + margin
    canvas_w = margin + n_cols * (cell_w + margin)
    canvas = np.ones((canvas_h, canvas_w, 3), dtype=np.uint8) * 255
    
    # åˆ—æ ‡é¢˜
    for col_idx, label in enumerate(col_labels):
        x = margin + col_idx * (cell_w + margin) + cell_w // 2 - 30
        cv2.putText(canvas, label, (x, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)
    
    # æ¯ä¸ªæ–¹æ³•çš„ç»“æœ
    for method_idx, (method_name, data) in enumerate(methods_data.items()):
        y_offset = label_h + method_idx * (cell_h + margin)
        
        images = [
            data.get('image'),
            data.get('heatmap'),
            data.get('boxes'),
            data.get('masks')
        ]
        
        for col_idx, img in enumerate(images):
            if img is None:
                continue
            
            if len(img.shape) == 2:
                img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
            
            img_resized = cv2.resize(img, (cell_w, cell_h))
            
            x_offset = margin + col_idx * (cell_w + margin)
            canvas[y_offset:y_offset+cell_h, x_offset:x_offset+cell_w] = img_resized
        
        # æ–¹æ³•æ ‡ç­¾
        label_text = method_labels.get(method_name, method_name)
        cv2.putText(canvas, label_text, (5, y_offset + cell_h // 2),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)
    
    cv2.imwrite(str(output_path), canvas)
    print(f"âœ… å¯¹æ¯”ç½‘æ ¼å›¾: {output_path}")


def create_summary_report(results, output_path):
    """åˆ›å»ºæ–‡å­—å¯¹æ¯”æŠ¥å‘Š"""
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("DINOv3 çƒ­å›¾æ–¹æ³•å¯¹æ¯”æŠ¥å‘Š\n")
        f.write("=" * 80 + "\n\n")
        
        f.write(f"{'æ–¹æ³•':<20} {'Boxes':<10} {'æ€»Masks':<12} {'æœ‰æ•ˆMasks':<12} {'æœ‰æ•ˆç‡':<10}\n")
        f.write("-" * 80 + "\n")
        
        for method, stats in results.items():
            valid_rate = (stats['valid_masks'] / stats['total_masks'] * 100) if stats['total_masks'] > 0 else 0
            f.write(f"{method:<20} {stats['boxes']:<10} {stats['total_masks']:<12} "
                   f"{stats['valid_masks']:<12} {valid_rate:>8.1f}%\n")
        
        best = max(results.items(), key=lambda x: x[1]['valid_masks'])
        
        f.write("\n" + "=" * 80 + "\n")
        f.write(f"ğŸ† æ¨èæ–¹æ³•: {best[0].upper()}\n")
        f.write(f"   æœ‰æ•ˆæ©ç æ•°: {best[1]['valid_masks']}\n")
        f.write("=" * 80 + "\n")


def main():
    print("=" * 80)
    print("DINOv3 çƒ­å›¾æ–¹æ³•å¯è§†åŒ–å¯¹æ¯”æµ‹è¯•")
    print("=" * 80)
    
    # é…ç½®
    image_path = "/media/pc/D/datasets/vkitti2/Scene01/clone/frames/rgb/Camera_0/rgb_00061.jpg"
    output_dir = Path("/media/pc/D/zhaochen/mono3d/mono3d/outputs/quick_comparison_visual")
    output_dir.mkdir(exist_ok=True, parents=True)
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    area_threshold = 300
    
    print(f"\nğŸ“‹ é…ç½®:")
    print(f"  å›¾åƒ: {Path(image_path).name}")
    print(f"  è®¾å¤‡: {device}")
    print(f"  è¾“å‡º: {output_dir}")
    
    # åŠ è½½å›¾åƒ
    print(f"\nğŸ“· åŠ è½½å›¾åƒ...")
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    image_size = (image.shape[1], image.shape[0])
    print(f"   âœ… {image_size[0]}x{image_size[1]}")
    
    cv2.imwrite(str(output_dir / "00_original.jpg"),
               cv2.cvtColor(image, cv2.COLOR_RGB2BGR))
    
    # åŠ è½½æ¨¡å‹
    print(f"\nğŸ”§ åŠ è½½æ¨¡å‹...")
    dinov3_model = torch.hub.load(
        '/media/pc/D/zhaochen/mono3d/dinov3',
        'dinov3_vith16plus',
        source='local',
        trust_repo=True,
        pretrained=False
    )
    state = torch.load(
        '/media/pc/D/zhaochen/mono3d/dinov3/checkpoints/dinov3_vith16plus.pth',
        map_location='cpu'
    )
    dinov3_model.load_state_dict(state, strict=False)
    dinov3_model = dinov3_model.to(device).eval()
    print(f"   âœ… DINOv3")
    
    sam2_predictor = load_sam2_model(device)
    if sam2_predictor:
        print(f"   âœ… SAM2")
    
    # æµ‹è¯•ä¸‰ç§æ–¹æ³•
    methods = ['objectness', 'combined', 'attention']
    results = {}
    methods_data = {}
    
    for method in methods:
        print(f"\n{'='*80}")
        print(f"ğŸ“Š æµ‹è¯•æ–¹æ³•: {method.upper()}")
        print(f"{'='*80}")
        
        method_dir = output_dir / method
        method_dir.mkdir(exist_ok=True)
        
        # åˆ›å»ºæå–å™¨
        extractor = ImprovedDINOv3Extractor(dinov3_model, device, heatmap_method=method)
        
        # ç”Ÿæˆçƒ­å›¾
        print(f"   ç”Ÿæˆçƒ­å›¾...")
        heatmap = extractor.generate_heatmap(image, image_size)
        print(f"   â”œâ”€ èŒƒå›´: [{heatmap.min():.3f}, {heatmap.max():.3f}]")
        print(f"   â”œâ”€ å‡å€¼: {heatmap.mean():.3f}")
        print(f"   â””â”€ æ ‡å‡†å·®: {heatmap.std():.3f}")
        
        heatmap_colored, heatmap_stats = save_heatmap(heatmap, image, method_dir)
        
        # ç”Ÿæˆå€™é€‰æ¡†
        print(f"   ç”Ÿæˆå€™é€‰æ¡†...")
        boxes = heatmap_to_boxes(heatmap, percentile=95, smoothing_kernel=11, min_component_area=4000)
        print(f"   â””â”€ {len(boxes)}ä¸ªboxes")
        
        save_boxes(image, boxes, method_dir)
        
        if not boxes:
            print(f"   âš ï¸  è·³è¿‡SAM2")
            results[method] = {
                'boxes': 0, 'total_masks': 0, 'valid_masks': 0,
                'avg_area': 0, 'max_area': 0,
                'heatmap_min': heatmap_stats['min'],
                'heatmap_max': heatmap_stats['max'],
                'heatmap_mean': heatmap_stats['mean'],
                'heatmap_std': heatmap_stats['std']
            }
            methods_data[method] = {
                'image': cv2.cvtColor(image, cv2.COLOR_RGB2BGR),
                'heatmap': heatmap_colored,
                'boxes': cv2.cvtColor(image, cv2.COLOR_RGB2BGR),
                'masks': cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
            }
            continue
        
        # SAM2åˆ†å‰²
        print(f"   è¿è¡ŒSAM2...")
        masks = segment_with_sam2(sam2_predictor, image, boxes, device)
        print(f"   â””â”€ {len(masks)}ä¸ªmasks")
        
        valid_masks = save_masks(image, masks, area_threshold, method_dir)
        print(f"   âœ… {len(valid_masks)}ä¸ªæœ‰æ•ˆmasks")
        
        # ç»Ÿè®¡
        total_area = sum(m[2] for m in valid_masks) if valid_masks else 0
        max_area = max((m[2] for m in valid_masks), default=0)
        avg_area = total_area / len(valid_masks) if valid_masks else 0
        
        results[method] = {
            'boxes': len(boxes),
            'total_masks': len(masks),
            'valid_masks': len(valid_masks),
            'avg_area': avg_area,
            'max_area': max_area,
            'heatmap_min': heatmap_stats['min'],
            'heatmap_max': heatmap_stats['max'],
            'heatmap_mean': heatmap_stats['mean'],
            'heatmap_std': heatmap_stats['std']
        }
        
        # å‡†å¤‡å¯¹æ¯”æ•°æ®
        boxes_img = cv2.imread(str(method_dir / "04_boxes_detail.jpg"))
        masks_img = cv2.imread(str(method_dir / "06_masks_overlay.jpg"))
        
        methods_data[method] = {
            'image': cv2.cvtColor(image, cv2.COLOR_RGB2BGR),
            'heatmap': heatmap_colored,
            'boxes': boxes_img if boxes_img is not None else cv2.cvtColor(image, cv2.COLOR_RGB2BGR),
            'masks': masks_img if masks_img is not None else cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        }
    
    # ç”Ÿæˆå¯¹æ¯”
    print(f"\n{'='*80}")
    print("ğŸ“Š ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š")
    print(f"{'='*80}")
    
    create_comparison_grid(methods_data, output_dir / "comparison_grid.jpg")
    create_summary_report(results, output_dir / "comparison_summary.txt")
    
    # æ‰“å°æ€»ç»“
    print(f"\n{'='*80}")
    print("ğŸ“ˆ ç»“æœå¯¹æ¯”")
    print(f"{'='*80}\n")
    
    print(f"{'æ–¹æ³•':<15} {'Boxes':<10} {'æ€»Masks':<12} {'æœ‰æ•ˆMasks':<12} {'æœ‰æ•ˆç‡':<10}")
    print("-" * 65)
    
    for method in methods:
        r = results[method]
        valid_rate = (r['valid_masks'] / r['total_masks'] * 100) if r['total_masks'] > 0 else 0
        print(f"{method:<15} {r['boxes']:<10} {r['total_masks']:<12} "
              f"{r['valid_masks']:<12} {valid_rate:>8.1f}%")
    
    best = max(results.items(), key=lambda x: x[1]['valid_masks'])
    
    print(f"\n{'='*80}")
    print(f"ğŸ† æ¨èæ–¹æ³•: {best[0].upper()}")
    print(f"   æœ‰æ•ˆMasks: {best[1]['valid_masks']}")
    print(f"{'='*80}")
    
    print(f"\nğŸ’¾ è¾“å‡ºä½ç½®: {output_dir}/")
    print(f"   â”œâ”€â”€ comparison_grid.jpg")
    print(f"   â”œâ”€â”€ comparison_summary.txt")
    print(f"   â”œâ”€â”€ objectness/")
    print(f"   â”œâ”€â”€ combined/")
    print(f"   â””â”€â”€ attention/")


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()