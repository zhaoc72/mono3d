"""ä½¿ç”¨å®˜æ–¹DINOv3ä»£ç çš„é›¶æ ·æœ¬å®ä¾‹åˆ†å‰²ç®¡é“"""
from __future__ import annotations

import sys
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import torch
import torch.nn as nn
from torchvision import transforms
from PIL import Image

from .utils import LOGGER


class OfficialDINOv3Pipeline:
    """ä½¿ç”¨å®˜æ–¹DINOv3ä»£ç çš„å®Œæ•´ç®¡é“"""
    
    def __init__(
        self,
        config: Dict[str, Any],
        device: Optional[str] = None,
    ):
        self.config = config
        self.official_config = config.get('dinov3_official') or config.get('model', {}).get('dinov3_official', {})
        self.repo_dir = self.official_config['repo_dir']
        
        # æ·»åŠ å®˜æ–¹ä»£ç è·¯å¾„åˆ°Pythonè·¯å¾„
        if self.repo_dir not in sys.path:
            sys.path.insert(0, self.repo_dir)
        
        # å¤šGPUé…ç½®
        self.multi_gpu_config = self.official_config.get('multi_gpu', {})
        self.use_multi_gpu = self.multi_gpu_config.get('enabled', True)
        self.num_gpus = torch.cuda.device_count()
        
        if self.use_multi_gpu and self.num_gpus >= 2:
            LOGGER.info(f"ğŸš€ Multi-GPU enabled: {self.num_gpus} GPUs detected")
            self.device = torch.device("cuda:0")  # ä¸»è®¾å¤‡
        else:
            self.device = torch.device(device or "cuda")
            LOGGER.info(f"ğŸ“Œ Single GPU mode: {self.device}")
        
        # æ¨ç†é…ç½®
        self.inference_config = self.official_config['inference']
        self.image_size = self.inference_config['image_size']
        self.dtype = self._resolve_dtype(self.inference_config['dtype'])
        
        # åŠ è½½æ¨¡å‹
        self._load_models()
        
        # å›¾åƒé¢„å¤„ç†
        self.transform = self._make_transform(self.image_size)
    
    @staticmethod
    def _resolve_dtype(dtype_str: str) -> torch.dtype:
        """è§£ædtypeå­—ç¬¦ä¸²"""
        lookup = {
            "float16": torch.float16,
            "float32": torch.float32,
            "bfloat16": torch.bfloat16,
        }
        return lookup.get(dtype_str.lower(), torch.bfloat16)
    
    def _make_transform(self, resize_size: int) -> transforms.Compose:
        """åˆ›å»ºå›¾åƒé¢„å¤„ç†pipeline"""
        resize = transforms.Resize((resize_size, resize_size))
        to_tensor = transforms.ToTensor()
        normalize = transforms.Normalize(
            mean=(0.485, 0.456, 0.406),
            std=(0.229, 0.224, 0.225),
        )
        return transforms.Compose([resize, to_tensor, normalize])
    
    def _load_models(self):
        """åŠ è½½æ‰€æœ‰æ¨¡å‹"""
        LOGGER.info("=" * 70)
        LOGGER.info("ğŸ§  Loading DINOv3 Official Models (Simplified Loading)")
        LOGGER.info("=" * 70)
        
        backbone_cfg = self.official_config['backbone']
        detection_cfg = self.official_config['detection']
        segmentation_cfg = self.official_config['segmentation']
        
        # ========== ç­–ç•¥ï¼šåªåŠ è½½ä¸€ä¸ªæ¨¡å‹ï¼Œåˆ†æ—¶å¤ç”¨ ==========
        # ç”±äºViT-7Bå¤ªå¤§ï¼Œæˆ‘ä»¬é‡‡ç”¨ï¼šå…ˆåŠ è½½æ£€æµ‹å™¨è·‘æ¨ç†ï¼Œç„¶åæ¸…ç©ºæ˜¾å­˜ï¼Œå†åŠ è½½åˆ†å‰²å™¨
        
        LOGGER.info("\nğŸ“ Note: Using sequential loading strategy due to model size")
        LOGGER.info("   - Detector and Segmentor will be loaded on-demand")
        LOGGER.info("   - This saves memory but requires loading twice per image")
        
        # ä¸åœ¨åˆå§‹åŒ–æ—¶åŠ è½½æ¨¡å‹ï¼Œè€Œæ˜¯åœ¨æ¨ç†æ—¶æŒ‰éœ€åŠ è½½
        self.detector = None
        self.segmentor = None
        
        # ä¿å­˜é…ç½®ä¾›åç»­åŠ è½½ä½¿ç”¨
        self.backbone_cfg = backbone_cfg
        self.detection_cfg = detection_cfg
        self.segmentation_cfg = segmentation_cfg
        
        LOGGER.info("=" * 70)
        LOGGER.info("âœ… Model loading strategy initialized")
        LOGGER.info("=" * 70)

    def _load_detector_if_needed(self):
        """æŒ‰éœ€åŠ è½½æ£€æµ‹å™¨"""
        if self.detector is not None:
            return
        
        LOGGER.info("ğŸ”„ Loading detector on-demand...")
        
        # å¦‚æœåˆ†å‰²å™¨åœ¨æ˜¾å­˜ä¸­ï¼Œå…ˆæ¸…ç†
        if self.segmentor is not None:
            LOGGER.info("   Clearing segmentor from memory...")
            del self.segmentor
            self.segmentor = None
            torch.cuda.empty_cache()
        
        self.detector = torch.hub.load(
            self.repo_dir,
            self.detection_cfg['model_name'],
            source="local",
            weights=self.detection_cfg['checkpoint_path'],
            backbone_weights=self.backbone_cfg['checkpoint_path'],
            trust_repo=True,
        )
        
        # ç§»åˆ°GPU 0
        self.detector = self.detector.to("cuda:3")
        self.detector.eval()
        
        LOGGER.info("   âœ… Detector loaded on GPU 3")
        
        if torch.cuda.is_available():
            allocated = torch.cuda.memory_allocated(0) / 1024**3
            LOGGER.info(f"   ğŸ’¾ GPU 0: {allocated:.2f}GB allocated")

    def _load_segmentor_if_needed(self):
        """æŒ‰éœ€åŠ è½½åˆ†å‰²å™¨"""
        if self.segmentor is not None:
            return
        
        LOGGER.info("ğŸ”„ Loading segmentor on-demand...")
        
        # å¦‚æœæ£€æµ‹å™¨åœ¨æ˜¾å­˜ä¸­ï¼Œå…ˆæ¸…ç†
        if self.detector is not None:
            LOGGER.info("   Clearing detector from memory...")
            del self.detector
            self.detector = None
            torch.cuda.empty_cache()
        
        self.segmentor = torch.hub.load(
            self.repo_dir,
            self.segmentation_cfg['model_name'],
            source="local",
            weights=self.segmentation_cfg['checkpoint_path'],
            backbone_weights=self.backbone_cfg['checkpoint_path'],
            trust_repo=True,
        )
        
        # ç§»åˆ°GPU 3
        self.segmentor = self.segmentor.to("cuda:0")
        self.segmentor.eval()
        
        LOGGER.info("   âœ… Segmentor loaded on GPU 0")
        
        if torch.cuda.is_available():
            allocated = torch.cuda.memory_allocated(0) / 1024**3
            LOGGER.info(f"   ğŸ’¾ GPU 3: {allocated:.2f}GB allocated")
    
    
    def _preprocess_image(self, image: np.ndarray) -> torch.Tensor:
        """é¢„å¤„ç†å›¾åƒ"""
        # è½¬æ¢ä¸ºPIL Image
        if isinstance(image, np.ndarray):
            pil_image = Image.fromarray(image)
        else:
            pil_image = image
        
        # åº”ç”¨transform
        tensor = self.transform(pil_image)
        return tensor.unsqueeze(0)  # æ·»åŠ batchç»´åº¦
    
    @torch.inference_mode()
    def run_detection(
    self,
    image: np.ndarray,
) -> Dict[str, Any]:
        """è¿è¡Œæ£€æµ‹"""
        LOGGER.info("ğŸ¯ Running detection...")
        
        # æŒ‰éœ€åŠ è½½æ£€æµ‹å™¨
        self._load_detector_if_needed()
        
        # é¢„å¤„ç†å¹¶ç§»åˆ°GPU 0
        batch_img = self._preprocess_image(image).to("cuda:0")
        
        # æ¨ç†
        predictions = self.detector(batch_img)
        
        # è§£æç»“æœ
        pred = predictions[0] if isinstance(predictions, list) else predictions
        
        boxes = pred['boxes'].cpu().numpy()
        scores = pred['scores'].cpu().numpy()
        labels = pred['labels'].cpu().numpy()
        
        # è¿‡æ»¤ä½åˆ†æ£€æµ‹
        threshold = self.official_config['detection']['score_threshold']
        valid_mask = scores >= threshold
        
        result = {
            'boxes': boxes[valid_mask],
            'scores': scores[valid_mask],
            'labels': labels[valid_mask],
            'num_detections': int(valid_mask.sum()),
        }
        
        LOGGER.info(f"   âœ… Detected {result['num_detections']} objects")
        return result
    
    @torch.inference_mode()
    def run_segmentation(
    self,
    image: np.ndarray,
) -> Dict[str, Any]:
        """è¿è¡Œåˆ†å‰²"""
        LOGGER.info("ğŸ–¼ï¸  Running segmentation...")
        
        # æŒ‰éœ€åŠ è½½åˆ†å‰²å™¨
        self._load_segmentor_if_needed()
        
        # å¯¼å…¥åˆ†å‰²æ¨ç†å·¥å…·
        from dinov3.eval.segmentation.inference import make_inference
        from functools import partial
        
        seg_cfg = self.official_config['segmentation']
        inf_cfg = self.inference_config
        
        # é¢„å¤„ç†
        pil_image = Image.fromarray(image) if isinstance(image, np.ndarray) else image
        original_size = pil_image.size  # (W, H)
        
        # ç§»åˆ°GPU 0
        batch_img = self._preprocess_image(image).to("cuda:0")
        
        # æ»‘çª—æ¨ç†
        segmentation_map = make_inference(
            batch_img,
            self.segmentor,
            inference_mode=seg_cfg.get('inference_mode', 'slide'),
            decoder_head_type=seg_cfg.get('decoder_head_type', 'm2f'),
            rescale_to=original_size,
            n_output_channels=seg_cfg['num_classes'],
            crop_size=tuple(inf_cfg['crop_size']),
            stride=tuple(inf_cfg['stride']),
            output_activation=partial(torch.nn.functional.softmax, dim=1),
        )
        
        # è½¬æ¢ä¸ºnumpy
        probs = segmentation_map[0].cpu().numpy()
        class_map = segmentation_map.argmax(dim=1, keepdim=False)[0].cpu().numpy()
        
        result = {
            'probs': probs,
            'class_map': class_map,
            'num_classes': seg_cfg['num_classes'],
        }
        
        LOGGER.info(f"   âœ… Segmentation complete: {result['num_classes']} classes")
        return result
    
    def run(self, image: np.ndarray) -> Dict[str, Any]:
        """å®Œæ•´æ¨ç†ç®¡é“"""
        LOGGER.info("\n" + "=" * 70)
        LOGGER.info("ğŸš€ Running Official DINOv3 Pipeline")
        LOGGER.info("=" * 70)
        
        # è¿è¡Œæ£€æµ‹
        detection_result = self.run_detection(image)
        
        # è¿è¡Œåˆ†å‰²
        segmentation_result = self.run_segmentation(image)
        
        # åˆå¹¶ç»“æœ
        result = {
            'detection': detection_result,
            'segmentation': segmentation_result,
            'image_shape': image.shape[:2],
            'processed_size': (self.image_size, self.image_size),
        }
        
        LOGGER.info("=" * 70)
        LOGGER.info("âœ… Pipeline complete")
        LOGGER.info("=" * 70)
        
        return result