#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•è„šæœ¬ - å¯¹æ¯”ä¸‰ç§æ–¹æ³•çš„æ•ˆæœ

è¿™ä¸ªè„šæœ¬ä¼šå¿«é€Ÿå±•ç¤ºä¸‰ç§æ–¹æ³•çš„:
1. çƒ­å›¾è´¨é‡
2. ç”Ÿæˆçš„promptsæ•°é‡
3. SAM2åˆ†å‰²ç»“æœ
"""

import sys
sys.path.insert(0, '/media/pc/D/zhaochen/mono3d/mono3d')

import yaml
import torch
import numpy as np
import cv2
from pathlib import Path

from src.sam2_segmenter import SAM2Segmenter, Sam2Config
from src.prompt_generator import PromptConfig, generate_prompts_from_heatmap
from src.data_loader import load_image
from src.utils import to_torch_dtype

# å¯¼å…¥æ”¹è¿›çš„æå–å™¨
sys.path.insert(0, '/home/claude')
from improved_dinov3_extractor import ImprovedDINOv3Extractor


def quick_test():
    print("=" * 80)
    print("DINOv3 çƒ­å›¾æ–¹æ³•å¿«é€Ÿå¯¹æ¯”æµ‹è¯•")
    print("=" * 80)
    
    # é…ç½®è·¯å¾„
    image_path = "/media/pc/D/datasets/vkitti2/Scene01/clone/frames/rgb/Camera_0/rgb_00061.jpg"
    config_path = "/media/pc/D/zhaochen/mono3d/mono3d/configs/model_config.yaml"
    prompt_config_path = "/media/pc/D/zhaochen/mono3d/mono3d/configs/prompt_config.yaml"
    
    output_dir = Path("/media/pc/D/zhaochen/mono3d/mono3d/outputs/quick_comparison")
    output_dir.mkdir(exist_ok=True, parents=True)
    
    # åŠ è½½å›¾åƒ
    print(f"\nğŸ“· åŠ è½½å›¾åƒ: {Path(image_path).name}")
    sample = load_image(image_path)
    image_size = (sample.image.shape[1], sample.image.shape[0])
    print(f"   å¤§å°: {image_size[0]}x{image_size[1]}")
    
    # ä¿å­˜åŸå›¾
    cv2.imwrite(
        str(output_dir / "original.jpg"),
        cv2.cvtColor(sample.image, cv2.COLOR_RGB2BGR)
    )
    
    # åŠ è½½é…ç½®
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    with open(prompt_config_path, 'r') as f:
        prompt_cfg_dict = yaml.safe_load(f)
    
    device = torch.device(config["device"])
    dtype = to_torch_dtype(config["dtype"])
    
    # åŠ è½½DINOv3æ¨¡å‹
    print("\nğŸ”§ åŠ è½½DINOv3æ¨¡å‹...")
    model = torch.hub.load(
        config["dinov3"]["repo_or_dir"],
        config["dinov3"]["model_name"],
        source="local",
        trust_repo=True,
        pretrained=False
    )
    
    state = torch.load(config["dinov3"]["checkpoint_path"], map_location="cpu")
    model.load_state_dict(state, strict=False)
    model = model.to(device).eval()
    print("   âœ… DINOv3å°±ç»ª")
    
    # åŠ è½½SAM2
    print("\nğŸ”§ åŠ è½½SAM2æ¨¡å‹...")
    sam2_cfg = Sam2Config(**config["sam2"])
    segmenter = SAM2Segmenter(sam2_cfg, device, dtype)
    print("   âœ… SAM2å°±ç»ª")
    
    # Prompté…ç½®
    prompt_params = {}
    if "attention" in prompt_cfg_dict:
        prompt_params.update(prompt_cfg_dict["attention"])
    if "points" in prompt_cfg_dict:
        prompt_params.update(prompt_cfg_dict["points"])
    prompt_config = PromptConfig(**prompt_params)
    area_threshold = config["pipeline"]["area_threshold"]
    
    # æµ‹è¯•ä¸‰ç§æ–¹æ³•
    methods = ['objectness', 'combined', 'attention']
    results = {}
    
    for method in methods:
        print(f"\n{'='*80}")
        print(f"ğŸ“Š æµ‹è¯•æ–¹æ³•: {method.upper()}")
        print(f"{'='*80}")
        
        # åˆ›å»ºæå–å™¨
        extractor = ImprovedDINOv3Extractor(model, device, heatmap_method=method)
        
        # ç”Ÿæˆçƒ­å›¾
        print(f"   ç”Ÿæˆçƒ­å›¾...")
        heatmap = extractor.generate_heatmap(sample.image, image_size)
        
        print(f"   â”œâ”€ èŒƒå›´: [{heatmap.min():.3f}, {heatmap.max():.3f}]")
        print(f"   â”œâ”€ å‡å€¼: {heatmap.mean():.3f}")
        print(f"   â””â”€ æ ‡å‡†å·®: {heatmap.std():.3f}")
        
        # ä¿å­˜çƒ­å›¾
        heatmap_vis = (heatmap * 255).astype(np.uint8)
        heatmap_colored = cv2.applyColorMap(heatmap_vis, cv2.COLORMAP_JET)
        
        overlay = cv2.addWeighted(
            cv2.cvtColor(sample.image, cv2.COLOR_RGB2BGR), 0.6,
            heatmap_colored, 0.4, 0
        )
        cv2.imwrite(str(output_dir / f"{method}_heatmap.jpg"), overlay)
        
        # ç”Ÿæˆprompts
        print(f"   ç”Ÿæˆprompts...")
        boxes, points, labels = generate_prompts_from_heatmap(heatmap, prompt_config)
        
        print(f"   â””â”€ ç”Ÿæˆ{len(boxes)}ä¸ªboxes")
        
        if not boxes:
            print(f"   âš ï¸  æ²¡æœ‰ç”Ÿæˆä»»ä½•boxï¼Œè·³è¿‡SAM2")
            results[method] = {'boxes': 0, 'masks': 0, 'valid_masks': 0}
            continue
        
        # å¯è§†åŒ–boxes
        img_boxes = sample.image.copy()
        for i, box in enumerate(boxes[:10]):  # åªç”»å‰10ä¸ª
            x0, y0, x1, y1 = box
            cv2.rectangle(img_boxes, (x0, y0), (x1, y1), (0, 255, 0), 2)
        cv2.imwrite(
            str(output_dir / f"{method}_boxes.jpg"),
            cv2.cvtColor(img_boxes, cv2.COLOR_RGB2BGR)
        )
        
        # è¿è¡ŒSAM2
        print(f"   è¿è¡ŒSAM2åˆ†å‰²...")
        masks = segmenter.segment_batched(
            sample.image, boxes,
            points=points if points else None,
            labels=labels if labels else None,
            batch_size=32
        )
        
        # ç»Ÿè®¡æœ‰æ•ˆmasks
        valid_count = sum(1 for m in masks if m.sum() >= area_threshold)
        
        print(f"   â”œâ”€ ç”Ÿæˆ{len(masks)}ä¸ªmasks")
        print(f"   â””â”€ {valid_count}ä¸ªæœ‰æ•ˆmasks (â‰¥{area_threshold}px)")
        
        # å¯è§†åŒ–masks
        if masks:
            combined = np.zeros_like(sample.image)
            for i, mask in enumerate(masks):
                if mask.sum() >= area_threshold:  # åªæ˜¾ç¤ºæœ‰æ•ˆmasks
                    color = np.array([
                        (i * 50) % 255,
                        (i * 80) % 255,
                        (i * 120) % 255
                    ], dtype=np.uint8)
                    combined[mask.astype(bool)] = color
            
            overlay = cv2.addWeighted(
                cv2.cvtColor(sample.image, cv2.COLOR_RGB2BGR), 0.6,
                cv2.cvtColor(combined, cv2.COLOR_RGB2BGR), 0.4, 0
            )
            cv2.imwrite(str(output_dir / f"{method}_masks.jpg"), overlay)
        
        results[method] = {
            'boxes': len(boxes),
            'masks': len(masks),
            'valid_masks': valid_count
        }
    
    # æ‰“å°å¯¹æ¯”è¡¨æ ¼
    print(f"\n{'='*80}")
    print("ğŸ“ˆ ç»“æœå¯¹æ¯”")
    print(f"{'='*80}")
    
    print(f"\n{'æ–¹æ³•':<15} {'Boxes':<10} {'æ€»Masks':<12} {'æœ‰æ•ˆMasks':<12}")
    print("-" * 50)
    
    for method in methods:
        r = results[method]
        print(f"{method:<15} {r['boxes']:<10} {r['masks']:<12} {r['valid_masks']:<12}")
    
    # æ‰¾å‡ºæœ€ä½³æ–¹æ³•
    best = max(results.items(), key=lambda x: x[1]['valid_masks'])
    
    print(f"\n{'='*80}")
    print(f"ğŸ† æ¨èæ–¹æ³•: {best[0].upper()}")
    print(f"   æœ‰æ•ˆMasks: {best[1]['valid_masks']}")
    print(f"{'='*80}")
    
    print(f"\nğŸ’¾ ç»“æœä¿å­˜åœ¨: {output_dir}/")
    print("\næŸ¥çœ‹æ–‡ä»¶:")
    for method in methods:
        print(f"   {method}_heatmap.jpg - çƒ­å›¾")
        print(f"   {method}_boxes.jpg - Boxes")
        print(f"   {method}_masks.jpg - åˆ†å‰²ç»“æœ")
    
    # ç»™å‡ºå»ºè®®
    print(f"\n{'='*80}")
    print("ğŸ’¡ ä½¿ç”¨å»ºè®®")
    print(f"{'='*80}")
    
    if best[0] == 'objectness':
        print("\nç‰©ä½“æ€§æ–¹æ³•æ•ˆæœæœ€å¥½ï¼")
        print("åœ¨ dinov3_feature.py ä¸­ï¼Œæ›¿æ¢ attention_to_heatmap æ–¹æ³•ä¸ºç‰©ä½“æ€§æ–¹æ³•ã€‚")
    elif best[0] == 'combined':
        print("\nç»„åˆæ–¹æ³•æ•ˆæœæœ€å¥½ï¼")
        print("åœ¨ dinov3_feature.py ä¸­ï¼Œæ›¿æ¢ attention_to_heatmap æ–¹æ³•ä¸ºç»„åˆæ–¹æ³•ã€‚")
    else:
        print("\nå½“å‰attentionæ–¹æ³•å·²ç»ä¸é”™ã€‚")
        print("ä½†å¯ä»¥å°è¯•ç‰©ä½“æ€§æˆ–ç»„åˆæ–¹æ³•çœ‹æ˜¯å¦æœ‰æ”¹è¿›ã€‚")


if __name__ == "__main__":
    quick_test()